{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CS2_FinalModel_BS_Subject.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kD_j4v94OULk",
        "outputId": "4427fc2a-0d1a-4de5-9fc5-27889c1bf074"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFb8xjvWF4sV"
      },
      "source": [
        "import os\r\n",
        "os.chdir('drive/My Drive')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38YhRD0KeWNw"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "tf.compat.v1.enable_eager_execution()\r\n",
        "from tensorflow.keras.layers import TimeDistributed\r\n",
        "tf.keras.backend.clear_session()\r\n",
        "from tensorflow.keras.layers import Input, Softmax, RNN, Dense, Embedding, LSTM\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ2MTkLZOhGl"
      },
      "source": [
        "# !unzip archive.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5MSDpOMOk8x"
      },
      "source": [
        "import pandas as pd\r\n",
        "emails = pd.read_csv('emails.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "_jObjt4lO6tK",
        "outputId": "51c8bd20-0365-4287-f2e5-5edd1051db1f"
      },
      "source": [
        "emails.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>allen-p/_sent_mail/1.</td>\n",
              "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>allen-p/_sent_mail/10.</td>\n",
              "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>allen-p/_sent_mail/100.</td>\n",
              "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>allen-p/_sent_mail/1000.</td>\n",
              "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>allen-p/_sent_mail/1001.</td>\n",
              "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       file                                            message\n",
              "0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
              "1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
              "2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
              "3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
              "4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "O1IjFUb9O8Bj",
        "outputId": "317b30a9-1e65-4ca5-b70c-476a1b74fbfe"
      },
      "source": [
        "emails['message'][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Message-ID: <15464986.1075855378456.JavaMail.evans@thyme>\\nDate: Fri, 4 May 2001 13:51:00 -0700 (PDT)\\nFrom: phillip.allen@enron.com\\nTo: john.lavorato@enron.com\\nSubject: Re:\\nMime-Version: 1.0\\nContent-Type: text/plain; charset=us-ascii\\nContent-Transfer-Encoding: 7bit\\nX-From: Phillip K Allen\\nX-To: John J Lavorato <John J Lavorato/ENRON@enronXgate@ENRON>\\nX-cc: \\nX-bcc: \\nX-Folder: \\\\Phillip_Allen_Jan2002_1\\\\Allen, Phillip K.\\\\'Sent Mail\\nX-Origin: Allen-P\\nX-FileName: pallen (Non-Privileged).pst\\n\\nTraveling to have a business meeting takes the fun out of the trip.  Especially if you have to prepare a presentation.  I would suggest holding the business plan meetings here then take a trip without any formal business meetings.  I would even try and get some honest opinions on whether a trip is even desired or necessary.\\n\\nAs far as the business meetings, I think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not.  Too often the presenter speaks and the others are quiet just waiting for their turn.   The meetings might be better if held in a round table discussion format.  \\n\\nMy suggestion for where to go is Austin.  Play golf and rent a ski boat and jet ski's.  Flying somewhere takes too much time.\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpqvRfKrPQ69"
      },
      "source": [
        "import email\r\n",
        "def parse_func(x):\r\n",
        "  b = email.message_from_string(x)\r\n",
        "  body = ''\r\n",
        "  if b.is_multipart():\r\n",
        "    for payload in b.get_payload():\r\n",
        "      body = body+ ' '\r\n",
        "      body+=payload.get_payload()\r\n",
        "  else:\r\n",
        "    body+=b.get_payload()\r\n",
        "\r\n",
        "  return body"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt02EJhL7Pah"
      },
      "source": [
        "def parse_func_subj(x):\r\n",
        "  b = email.message_from_string(x)\r\n",
        "  if b.get('Subject'):\r\n",
        "    subj = b.get('Subject')\r\n",
        "  else:\r\n",
        "    subj = '-'\r\n",
        "  return subj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnHcaJryZdmv"
      },
      "source": [
        "emails['Body'] = emails['message'].apply(parse_func)\r\n",
        "emails['Subject'] = emails['message'].apply(parse_func_subj)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "_4B_d58k8Zag",
        "outputId": "bb047704-3b93-41f4-c3cd-f956497beeab"
      },
      "source": [
        "emails.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>message</th>\n",
              "      <th>Body</th>\n",
              "      <th>Subject</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>517396</th>\n",
              "      <td>zufferli-j/sent_items/95.</td>\n",
              "      <td>Message-ID: &lt;26807948.1075842029936.JavaMail.e...</td>\n",
              "      <td>This is a trade with OIL-SPEC-HEDGE-NG (John L...</td>\n",
              "      <td>Trade with John Lavorato</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517397</th>\n",
              "      <td>zufferli-j/sent_items/96.</td>\n",
              "      <td>Message-ID: &lt;25835861.1075842029959.JavaMail.e...</td>\n",
              "      <td>Some of my position is with the Alberta Term b...</td>\n",
              "      <td>Gas Hedges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517398</th>\n",
              "      <td>zufferli-j/sent_items/97.</td>\n",
              "      <td>Message-ID: &lt;28979867.1075842029988.JavaMail.e...</td>\n",
              "      <td>2\\n\\n -----Original Message-----\\nFrom: \\tDouc...</td>\n",
              "      <td>RE: CONFIDENTIAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517399</th>\n",
              "      <td>zufferli-j/sent_items/98.</td>\n",
              "      <td>Message-ID: &lt;22052556.1075842030013.JavaMail.e...</td>\n",
              "      <td>Analyst\\t\\t\\t\\t\\tRank\\n\\nStephane Brodeur\\t\\t\\...</td>\n",
              "      <td>Calgary Analyst/Associate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517400</th>\n",
              "      <td>zufferli-j/sent_items/99.</td>\n",
              "      <td>Message-ID: &lt;28618979.1075842030037.JavaMail.e...</td>\n",
              "      <td>i think the YMCA has a class that is for peopl...</td>\n",
              "      <td>RE: ali's essays</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             file  ...                    Subject\n",
              "517396  zufferli-j/sent_items/95.  ...   Trade with John Lavorato\n",
              "517397  zufferli-j/sent_items/96.  ...                 Gas Hedges\n",
              "517398  zufferli-j/sent_items/97.  ...           RE: CONFIDENTIAL\n",
              "517399  zufferli-j/sent_items/98.  ...  Calgary Analyst/Associate\n",
              "517400  zufferli-j/sent_items/99.  ...           RE: ali's essays\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MozTKVkO8AHm"
      },
      "source": [
        "def decontractions(phrase):\r\n",
        "  \"\"\"decontracted takes text and convert contractions into natural form.\r\n",
        "     ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\"\"\"\r\n",
        "\r\n",
        "  # specific\r\n",
        "  phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\r\n",
        "  phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\r\n",
        "  phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\r\n",
        "  phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\r\n",
        "\r\n",
        "  # general\r\n",
        "  phrase = re.sub(r\"n\\'t\", \" not\", phrase)\r\n",
        "  phrase = re.sub(r\"\\'re\", \" are\", phrase)\r\n",
        "  phrase = re.sub(r\"\\'s\", \" is\", phrase)\r\n",
        "  phrase = re.sub(r\"\\'d\", \" would\", phrase)\r\n",
        "  phrase = re.sub(r\"\\'ll\", \" will\", phrase)\r\n",
        "  phrase = re.sub(r\"\\'t\", \" not\", phrase)\r\n",
        "  phrase = re.sub(r\"\\'ve\", \" have\", phrase)\r\n",
        "  phrase = re.sub(r\"\\'m\", \" am\", phrase)\r\n",
        "\r\n",
        "  phrase = re.sub(r\"n\\’t\", \" not\", phrase)\r\n",
        "  phrase = re.sub(r\"\\’re\", \" are\", phrase)\r\n",
        "  phrase = re.sub(r\"\\’s\", \" is\", phrase)\r\n",
        "  phrase = re.sub(r\"\\’d\", \" would\", phrase)\r\n",
        "  phrase = re.sub(r\"\\’ll\", \" will\", phrase)\r\n",
        "  phrase = re.sub(r\"\\’t\", \" not\", phrase)\r\n",
        "  phrase = re.sub(r\"\\’ve\", \" have\", phrase)\r\n",
        "  phrase = re.sub(r\"\\’m\", \" am\", phrase)\r\n",
        "\r\n",
        "  return phrase"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZb2g2JyZj5L"
      },
      "source": [
        "'''Take the raw email body as input and clean the unnecessary text like \\n,\\t etc and also keep only alphabets and full stop(.)(for sentence separation)\r\n",
        "and replace extra spaces with one space and return clean text'''\r\n",
        "\r\n",
        "import re\r\n",
        "body = []\r\n",
        "for text in emails['Body']:\r\n",
        "  text = decontractions(text)\r\n",
        "  text = re.sub(r\"\\n|\\t\", ' ', text)\r\n",
        "  text = re.sub(\"[^a-zA-Z\\s.]+\",' ',text)\r\n",
        "  text = re.sub(\"\\s+\", ' ', text)\r\n",
        "  body.append(text)\r\n",
        "emails['Processed_Text'] = body\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "zKklTMHEH_J0",
        "outputId": "bc9f1983-0653-4a33-b9ed-1fbc8fdb7d48"
      },
      "source": [
        "'''Clean the subject of the mail by following the same steps as cleaning the email body including removing 're:' '''\r\n",
        "\r\n",
        "body = []\r\n",
        "for text in emails['Subject']:\r\n",
        "  text = text.lower()\r\n",
        "  text = re.sub('re:','',text)\r\n",
        "  text = decontractions(text)\r\n",
        "  text = re.sub(r\"\\n|\\t\", ' ', text)\r\n",
        "  text = re.sub(\"[^a-zA-Z\\s.]+\",' ',text)\r\n",
        "  text = re.sub(\"\\s+\", ' ', text)\r\n",
        "  body.append(text.strip())\r\n",
        "emails['Processed_Subject'] = body\r\n",
        "emails"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>message</th>\n",
              "      <th>Body</th>\n",
              "      <th>Subject</th>\n",
              "      <th>Processed_Text</th>\n",
              "      <th>Processed_Subject</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>allen-p/_sent_mail/1.</td>\n",
              "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
              "      <td>Here is our forecast\\n\\n</td>\n",
              "      <td>-</td>\n",
              "      <td>Here is our forecast</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>allen-p/_sent_mail/10.</td>\n",
              "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
              "      <td>Traveling to have a business meeting takes the...</td>\n",
              "      <td>Re:</td>\n",
              "      <td>Traveling to have a business meeting takes the...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>allen-p/_sent_mail/100.</td>\n",
              "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
              "      <td>test successful.  way to go!!!</td>\n",
              "      <td>Re: test</td>\n",
              "      <td>test successful. way to go</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>allen-p/_sent_mail/1000.</td>\n",
              "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
              "      <td>Randy,\\n\\n Can you send me a schedule of the s...</td>\n",
              "      <td>-</td>\n",
              "      <td>Randy Can you send me a schedule of the salary...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>allen-p/_sent_mail/1001.</td>\n",
              "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
              "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
              "      <td>Re: Hello</td>\n",
              "      <td>Let is shoot for Tuesday at .</td>\n",
              "      <td>hello</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517396</th>\n",
              "      <td>zufferli-j/sent_items/95.</td>\n",
              "      <td>Message-ID: &lt;26807948.1075842029936.JavaMail.e...</td>\n",
              "      <td>This is a trade with OIL-SPEC-HEDGE-NG (John L...</td>\n",
              "      <td>Trade with John Lavorato</td>\n",
              "      <td>This is a trade with OIL SPEC HEDGE NG John La...</td>\n",
              "      <td>trade with john lavorato</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517397</th>\n",
              "      <td>zufferli-j/sent_items/96.</td>\n",
              "      <td>Message-ID: &lt;25835861.1075842029959.JavaMail.e...</td>\n",
              "      <td>Some of my position is with the Alberta Term b...</td>\n",
              "      <td>Gas Hedges</td>\n",
              "      <td>Some of my position is with the Alberta Term b...</td>\n",
              "      <td>gas hedges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517398</th>\n",
              "      <td>zufferli-j/sent_items/97.</td>\n",
              "      <td>Message-ID: &lt;28979867.1075842029988.JavaMail.e...</td>\n",
              "      <td>2\\n\\n -----Original Message-----\\nFrom: \\tDouc...</td>\n",
              "      <td>RE: CONFIDENTIAL</td>\n",
              "      <td>Original Message From Doucet Dawn Sent Wednes...</td>\n",
              "      <td>confidential</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517399</th>\n",
              "      <td>zufferli-j/sent_items/98.</td>\n",
              "      <td>Message-ID: &lt;22052556.1075842030013.JavaMail.e...</td>\n",
              "      <td>Analyst\\t\\t\\t\\t\\tRank\\n\\nStephane Brodeur\\t\\t\\...</td>\n",
              "      <td>Calgary Analyst/Associate</td>\n",
              "      <td>Analyst Rank Stephane Brodeur Chad Clark Ian C...</td>\n",
              "      <td>calgary analyst associate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517400</th>\n",
              "      <td>zufferli-j/sent_items/99.</td>\n",
              "      <td>Message-ID: &lt;28618979.1075842030037.JavaMail.e...</td>\n",
              "      <td>i think the YMCA has a class that is for peopl...</td>\n",
              "      <td>RE: ali's essays</td>\n",
              "      <td>i think the YMCA has a class that is for peopl...</td>\n",
              "      <td>ali is essays</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>517401 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                             file  ...          Processed_Subject\n",
              "0           allen-p/_sent_mail/1.  ...                           \n",
              "1          allen-p/_sent_mail/10.  ...                           \n",
              "2         allen-p/_sent_mail/100.  ...                       test\n",
              "3        allen-p/_sent_mail/1000.  ...                           \n",
              "4        allen-p/_sent_mail/1001.  ...                      hello\n",
              "...                           ...  ...                        ...\n",
              "517396  zufferli-j/sent_items/95.  ...   trade with john lavorato\n",
              "517397  zufferli-j/sent_items/96.  ...                 gas hedges\n",
              "517398  zufferli-j/sent_items/97.  ...               confidential\n",
              "517399  zufferli-j/sent_items/98.  ...  calgary analyst associate\n",
              "517400  zufferli-j/sent_items/99.  ...              ali is essays\n",
              "\n",
              "[517401 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_3RQ64Ya3Xy",
        "outputId": "48bfeac4-4025-4495-8011-93688f4f863d"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "char_lengths = pd.Series([len(str(x)) for x in emails['Processed_Text']])\r\n",
        "\r\n",
        "char_lengths.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    3.447290e+05\n",
              "mean     1.413327e+03\n",
              "std      8.441524e+03\n",
              "min      1.000000e+00\n",
              "25%      1.650000e+02\n",
              "50%      4.220000e+02\n",
              "75%      1.099000e+03\n",
              "max      1.984612e+06\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTuKRyOHoBV-"
      },
      "source": [
        "We took the character lengths from each email and the stats are as follows.\r\n",
        "\r\n",
        "-Minimum value is 0 which means after cleaning some mails have 0 characters. We can remove them from our data as they wont be of any use. \r\n",
        "-Maximum value is 18 lakhs which is definitely an outlier. It might be mistakenly entered into the data or some particular mails might be lengthy. \r\n",
        "-We understood the above are outliers from the 75th percentile of data. Lenght is 1.5k which is normal length. \r\n",
        "\r\n",
        "To analyse further we shall see the sentence lengths and word lenghts of emails."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZR6KwDoZnKZ3",
        "outputId": "da2ba1ed-bd91-4057-b136-aab545521d6a"
      },
      "source": [
        "sentences = pd.Series([len(str(x).split('.')) for x in emails['Processed_Text']])\r\n",
        "sentences.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    344729.000000\n",
              "mean         19.256906\n",
              "std          74.460999\n",
              "min           1.000000\n",
              "25%           3.000000\n",
              "50%           7.000000\n",
              "75%          14.000000\n",
              "max       10520.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "RMcbpC94vQnH",
        "outputId": "d7ef4d0c-bff0-4678-81d7-3c31aebec036"
      },
      "source": [
        "emails['no_of_sent'] = sentences\r\n",
        "emails[emails['no_of_sent']>40]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>message</th>\n",
              "      <th>Body</th>\n",
              "      <th>Subject</th>\n",
              "      <th>Processed_Text</th>\n",
              "      <th>Processed_Subject</th>\n",
              "      <th>no_of_sent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>allen-p/_sent_mail/557.</td>\n",
              "      <td>Message-ID: &lt;16004214.1075855728430.JavaMail.e...</td>\n",
              "      <td>By STEVE EVERLY - The Kansas City Star\\nDate: ...</td>\n",
              "      <td>-</td>\n",
              "      <td>By STEVE EVERLY The Kansas City Star Date As n...</td>\n",
              "      <td></td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392</th>\n",
              "      <td>allen-p/all_documents/1.</td>\n",
              "      <td>Message-ID: &lt;29790972.1075855665306.JavaMail.e...</td>\n",
              "      <td>In today's Daily Update you'll find free repor...</td>\n",
              "      <td>December 14, 2000 - Bear Stearns' predictions ...</td>\n",
              "      <td>In today is Daily Update you will find free re...</td>\n",
              "      <td>december bear stearns predictions for telecom ...</td>\n",
              "      <td>135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>allen-p/all_documents/10.</td>\n",
              "      <td>Message-ID: &lt;21975671.1075855665520.JavaMail.e...</td>\n",
              "      <td>Here is today's copy of Bloomberg Power Lines....</td>\n",
              "      <td>Bloomberg Power Lines Report</td>\n",
              "      <td>Here is today is copy of Bloomberg Power Lines...</td>\n",
              "      <td>bloomberg power lines report</td>\n",
              "      <td>385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456</th>\n",
              "      <td>allen-p/all_documents/19.</td>\n",
              "      <td>Message-ID: &lt;29399491.1075855665902.JavaMail.e...</td>\n",
              "      <td>Y-Life Daily Bulletin: December 13, 2000\\n\\nNo...</td>\n",
              "      <td>Y-Life Daily: Bush will almost definitely be p...</td>\n",
              "      <td>Y Life Daily Bulletin December Note If your e ...</td>\n",
              "      <td>y life daily bush will almost definitely be pr...</td>\n",
              "      <td>124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463</th>\n",
              "      <td>allen-p/all_documents/2.</td>\n",
              "      <td>Message-ID: &lt;31189653.1075855665329.JavaMail.e...</td>\n",
              "      <td>As requested, here is the December Autoweb.com...</td>\n",
              "      <td>December Newsletter - Factory Incentives are a...</td>\n",
              "      <td>As requested here is the December Autoweb.com ...</td>\n",
              "      <td>december newsletter factory incentives are at ...</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344556</th>\n",
              "      <td>zufferli-j/deleted_items/82.</td>\n",
              "      <td>Message-ID: &lt;2065626.1075842023405.JavaMail.ev...</td>\n",
              "      <td>&lt;html&gt;&lt;head&gt;&lt;/head&gt;\\n&lt;body bgcolor=\"#ffffff\"&gt;&lt;...</td>\n",
              "      <td>Extended Websaver continues through January</td>\n",
              "      <td>html head head body bgcolor ffffff font color...</td>\n",
              "      <td>extended websaver continues through january</td>\n",
              "      <td>258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344561</th>\n",
              "      <td>zufferli-j/deleted_items/9.</td>\n",
              "      <td>Message-ID: &lt;3341011.1075842020660.JavaMail.ev...</td>\n",
              "      <td>\\n[IMAGE]=09\\n\\n\\n[IMAGE] [IMAGE][IMAGE][IMAGE...</td>\n",
              "      <td>Syncrasy Daily Trader Summary for Wed, Feb 06,...</td>\n",
              "      <td>IMAGE IMAGE IMAGE IMAGE IMAGE IMAGE IMAGE IMA...</td>\n",
              "      <td>syncrasy daily trader summary for wed feb</td>\n",
              "      <td>134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344564</th>\n",
              "      <td>zufferli-j/deleted_items/92.</td>\n",
              "      <td>Message-ID: &lt;11314126.1075842023658.JavaMail.e...</td>\n",
              "      <td>\\n[IMAGE]=09\\n\\n\\n[IMAGE] [IMAGE][IMAGE][IMAGE...</td>\n",
              "      <td>Syncrasy Daily Trader Summary for Tue, Jan 29,...</td>\n",
              "      <td>IMAGE IMAGE IMAGE IMAGE IMAGE IMAGE IMAGE IMA...</td>\n",
              "      <td>syncrasy daily trader summary for tue jan</td>\n",
              "      <td>142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344565</th>\n",
              "      <td>zufferli-j/deleted_items/93.</td>\n",
              "      <td>Message-ID: &lt;3550151.1075842023814.JavaMail.ev...</td>\n",
              "      <td>\\n\\nTransmission Expansion and Systems in Tran...</td>\n",
              "      <td>Upcoming Conferences</td>\n",
              "      <td>Transmission Expansion and Systems in Transit...</td>\n",
              "      <td>upcoming conferences</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344622</th>\n",
              "      <td>zufferli-j/inbox/quotes/32.</td>\n",
              "      <td>Message-ID: &lt;21065884.1075842026997.JavaMail.e...</td>\n",
              "      <td>&lt;&lt;Trades for 3/1/02&gt;&gt;  &lt;&lt;Trades for 2/1/02&gt;&gt; ...</td>\n",
              "      <td>Trades and end of day marks</td>\n",
              "      <td>Trades for Trades for Trades for For trades w...</td>\n",
              "      <td>trades and end of day marks</td>\n",
              "      <td>124</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26866 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                file  ... no_of_sent\n",
              "323          allen-p/_sent_mail/557.  ...         84\n",
              "392         allen-p/all_documents/1.  ...        135\n",
              "393        allen-p/all_documents/10.  ...        385\n",
              "456        allen-p/all_documents/19.  ...        124\n",
              "463         allen-p/all_documents/2.  ...         68\n",
              "...                              ...  ...        ...\n",
              "344556  zufferli-j/deleted_items/82.  ...        258\n",
              "344561   zufferli-j/deleted_items/9.  ...        134\n",
              "344564  zufferli-j/deleted_items/92.  ...        142\n",
              "344565  zufferli-j/deleted_items/93.  ...         43\n",
              "344622   zufferli-j/inbox/quotes/32.  ...        124\n",
              "\n",
              "[26866 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nLMQ9-8rWxl"
      },
      "source": [
        "Median sentence length is 9 sentences per email. As we saw above, there are outliers. Since our task is sentence completion, we can extract sentences from emails to create each sentence as a data point. After analysing the emails with high number of sentences, we found that mail is having multiple mails in a mail chain. So we need to see how to separate out the text from the data. Also we need to remove parts like Forwarded by, To, Cc, From etc from the text that have many sentences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ssw86F5MvkAI"
      },
      "source": [
        "#Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8wmo5p-OuOE"
      },
      "source": [
        "In some rows, there are mails that were forwarded by so we remove such emails as we want clean data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfWJfAIYFSib",
        "outputId": "942867e5-ac78-45e4-b09f-93052768fb38"
      },
      "source": [
        "'''To remove emails that has the words Original Message or Forwarded by'''\r\n",
        "remove=[]\r\n",
        "for i in emails.index:\r\n",
        "  text = emails.loc[i]['Body']\r\n",
        "  if ('Original Message' in text) or ('Forwarded by' in text):\r\n",
        "    remove.append(i)\r\n",
        "\r\n",
        "emails.drop(remove,axis=0,inplace=True)\r\n",
        "emails.reset_index(drop=True,inplace=True)\r\n",
        "emails.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 344729 entries, 0 to 344728\n",
            "Data columns (total 6 columns):\n",
            " #   Column             Non-Null Count   Dtype \n",
            "---  ------             --------------   ----- \n",
            " 0   file               344729 non-null  object\n",
            " 1   message            344729 non-null  object\n",
            " 2   Body               344729 non-null  object\n",
            " 3   Subject            344729 non-null  object\n",
            " 4   Processed_Text     344729 non-null  object\n",
            " 5   Processed_Subject  344729 non-null  object\n",
            "dtypes: object(6)\n",
            "memory usage: 15.8+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljuICXNpnE3j"
      },
      "source": [
        "emails_original = emails"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OoWzwz9j5rL"
      },
      "source": [
        "##Short sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0yAIHJrOQBa"
      },
      "source": [
        "Since there are many emails that have large number of sentences because there are mail chains present in the mails. Also in those chains there is a lot of unwanted text which won't be of any use for us. So we here take emails that have less than 10 sentences for our task. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFomfQvHltFq",
        "outputId": "2040facc-ad03-477f-8b3f-84dda5bd3a3f"
      },
      "source": [
        "'''Take mails that have less than 10 sentences'''\r\n",
        "emails = emails_original[emails_original['no_of_sent']<10]\r\n",
        "emails.reset_index(drop=True,inplace=True)\r\n",
        "emails.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 216479 entries, 0 to 216478\n",
            "Data columns (total 7 columns):\n",
            " #   Column             Non-Null Count   Dtype \n",
            "---  ------             --------------   ----- \n",
            " 0   file               216479 non-null  object\n",
            " 1   message            216479 non-null  object\n",
            " 2   Body               216479 non-null  object\n",
            " 3   Subject            216479 non-null  object\n",
            " 4   Processed_Text     216479 non-null  object\n",
            " 5   Processed_Subject  216479 non-null  object\n",
            " 6   no_of_sent         216479 non-null  int64 \n",
            "dtypes: int64(1), object(6)\n",
            "memory usage: 11.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mJu6H0moDUg"
      },
      "source": [
        "'''Take sentences which have word length in range 5 and 12, split the sentence at each word to prepare inputs and outputs. \r\n",
        "To inputs add subject of the mail'''\r\n",
        "\r\n",
        "input = []\r\n",
        "output = []\r\n",
        "for i in emails.index:\r\n",
        "  subject = emails.loc[i]['Processed_Subject']\r\n",
        "  sentences = emails.loc[i]['Processed_Text'].split('.')\r\n",
        "  for sent in sentences:\r\n",
        "    sent = sent.lower()\r\n",
        "    noof_words = len(sent.split())\r\n",
        "    if noof_words in range(5,13):\r\n",
        "      # half = int(noof_words/2)\r\n",
        "      words = sent.split()\r\n",
        "      for i in range(3,noof_words):\r\n",
        "        if i%3==0:\r\n",
        "          if noof_words-i>=4:\r\n",
        "            input.append(' '.join(subject.split()[:5]+words[:i]))\r\n",
        "            output.append(' '.join(words[i:i+4]))\r\n",
        "        elif i%3==1:\r\n",
        "          if noof_words-i>=3:\r\n",
        "            input.append(' '.join(subject.split()[:5]+words[:i]))\r\n",
        "            output.append(' '.join(words[i:i+3]))\r\n",
        "        else:\r\n",
        "          if noof_words-i>=2:\r\n",
        "            input.append(' '.join(subject.split()[:5]+words[:i]))\r\n",
        "            output.append(' '.join(words[i:i+2]))\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "INA6erPxoTHN",
        "outputId": "d884a6b3-8ff5-4d3c-e53e-f1e9f5100a6e"
      },
      "source": [
        "data_short = pd.DataFrame(columns=['input','output'])\r\n",
        "data_short['input']=input\r\n",
        "data_short['output']=output\r\n",
        "data_short.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>plus your thoughts</td>\n",
              "      <td>on any changes that</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>plus your thoughts on</td>\n",
              "      <td>any changes that</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>plus your thoughts on any</td>\n",
              "      <td>changes that</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>plus your thoughts on any changes</td>\n",
              "      <td>that need to be</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>plus your thoughts on any changes that</td>\n",
              "      <td>need to be</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    input               output\n",
              "0                      plus your thoughts  on any changes that\n",
              "1                   plus your thoughts on     any changes that\n",
              "2               plus your thoughts on any         changes that\n",
              "3       plus your thoughts on any changes      that need to be\n",
              "4  plus your thoughts on any changes that           need to be"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2ET0oZGj-hK"
      },
      "source": [
        "##Longer sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Cn3PBlZvmEE",
        "outputId": "37403fbf-f1f9-4f61-d058-6993cf8af248"
      },
      "source": [
        "emails = emails_original[emails_original['no_of_sent']<10]\r\n",
        "emails.reset_index(drop=True,inplace=True)\r\n",
        "emails.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 216479 entries, 0 to 216478\n",
            "Data columns (total 7 columns):\n",
            " #   Column             Non-Null Count   Dtype \n",
            "---  ------             --------------   ----- \n",
            " 0   file               216479 non-null  object\n",
            " 1   message            216479 non-null  object\n",
            " 2   Body               216479 non-null  object\n",
            " 3   Subject            216479 non-null  object\n",
            " 4   Processed_Text     216479 non-null  object\n",
            " 5   Processed_Subject  216479 non-null  object\n",
            " 6   no_of_sent         216479 non-null  int64 \n",
            "dtypes: int64(1), object(6)\n",
            "memory usage: 11.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K-YeFLb4Vty"
      },
      "source": [
        "'''Take sentences which have word length in range 10 and 14, split the sentence at each word to prepare inputs and outputs. \r\n",
        "To inputs add subject of the mail'''\r\n",
        "\r\n",
        "import random\r\n",
        "input = []\r\n",
        "output = []\r\n",
        "for i in emails.index:\r\n",
        "  subject = emails.loc[i]['Processed_Subject']\r\n",
        "  sentences = emails.loc[i]['Processed_Text'].split('.')\r\n",
        "  for sent in sentences:\r\n",
        "    sent = sent.lower()\r\n",
        "    noof_words = len(sent.split())\r\n",
        "    if noof_words in range(10,15):\r\n",
        "      # half = int(noof_words/2)\r\n",
        "      words = sent.split()\r\n",
        "      for i in range(10,noof_words):\r\n",
        "        rn = random.randint(3,6)\r\n",
        "        if noof_words-i>=rn:\r\n",
        "          input.append(' '.join(subject.split()[:5]+words[:i]))\r\n",
        "          output.append(' '.join(words[i:i+rn]))\r\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "EGJvnqczJLla",
        "outputId": "ae973ad5-267a-4dc8-ba57-23d91d60bad1"
      },
      "source": [
        "data_long = pd.DataFrame(columns=['input','output'])\r\n",
        "data_long['input']=input\r\n",
        "data_long['output']=output\r\n",
        "data_long.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>com monique sanchez frank ermis john lavorato ...</td>\n",
              "      <td>your help phillip allen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>john denver is short rockies position beyond i...</td>\n",
              "      <td>their trailblazer transport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>burnet i would also like to review the closing...</td>\n",
              "      <td>soon as possible</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>western gas market report draft richard compar...</td>\n",
              "      <td>california gas report</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cooper can you give access to the new west power</td>\n",
              "      <td>site to jay</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               input                       output\n",
              "0  com monique sanchez frank ermis john lavorato ...      your help phillip allen\n",
              "1  john denver is short rockies position beyond i...  their trailblazer transport\n",
              "2  burnet i would also like to review the closing...             soon as possible\n",
              "3  western gas market report draft richard compar...        california gas report\n",
              "4   cooper can you give access to the new west power                  site to jay"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knhkYRL8pYmM"
      },
      "source": [
        "##Word breaking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NR3M6ZXApfRg",
        "outputId": "9c86a065-135f-4053-ed68-ebb3cacb7821"
      },
      "source": [
        "emails = emails_original[emails_original['no_of_sent']<10]\r\n",
        "emails.reset_index(drop=True,inplace=True)\r\n",
        "emails.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 216479 entries, 0 to 216478\n",
            "Data columns (total 7 columns):\n",
            " #   Column             Non-Null Count   Dtype \n",
            "---  ------             --------------   ----- \n",
            " 0   file               216479 non-null  object\n",
            " 1   message            216479 non-null  object\n",
            " 2   Body               216479 non-null  object\n",
            " 3   Subject            216479 non-null  object\n",
            " 4   Processed_Text     216479 non-null  object\n",
            " 5   Processed_Subject  216479 non-null  object\n",
            " 6   no_of_sent         216479 non-null  int64 \n",
            "dtypes: int64(1), object(6)\n",
            "memory usage: 11.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4v914Bip-lA"
      },
      "source": [
        "'''Take sentences which have word length in range 5 and 12, split the sentence at each word by splitting the word into halves\r\n",
        " by putting first half in input and other half in output. To inputs add subject of the mail'''\r\n",
        "\r\n",
        "input = []\r\n",
        "output = []\r\n",
        "for i in emails.index:\r\n",
        "  subject = emails.loc[i]['Processed_Subject']\r\n",
        "  sentences = emails.loc[i]['Processed_Text'].split('.')\r\n",
        "  for sent in sentences:\r\n",
        "    sent = sent.lower()\r\n",
        "    noof_words = len(sent.split())\r\n",
        "    if noof_words in range(5,13):\r\n",
        "      # half = int(noof_words/2)\r\n",
        "      words = sent.split()\r\n",
        "      for i in range(3,noof_words):\r\n",
        "        if len(words[i])>=5 and noof_words-i>=3:\r\n",
        "          for j in range(3,len(words[i])):\r\n",
        "            if len(words[i])-j>=2:\r\n",
        "              half_word_1 = words[i][:j]\r\n",
        "              half_word_2 = words[i][j:]\r\n",
        "              input.append(' '.join(subject.split()[:5]+words[:i-1]+[half_word_1]))\r\n",
        "              output.append(' '.join([half_word_2]+words[i+1:i+3]))\r\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "sP1SWAa7qIHz",
        "outputId": "b5736094-65c2-4d8c-d42b-52bede3c7e14"
      },
      "source": [
        "data_wordbrk = pd.DataFrame(columns=['input','output'])\r\n",
        "data_wordbrk['input']=input\r\n",
        "data_wordbrk['output']=output\r\n",
        "data_wordbrk.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>plus your thoughts on cha</td>\n",
              "      <td>nges that need</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>plus your thoughts on chan</td>\n",
              "      <td>ges that need</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>plus your thoughts on chang</td>\n",
              "      <td>es that need</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hello greg how eit</td>\n",
              "      <td>her next tuesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hello greg how eith</td>\n",
              "      <td>er next tuesday</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         input            output\n",
              "0    plus your thoughts on cha    nges that need\n",
              "1   plus your thoughts on chan     ges that need\n",
              "2  plus your thoughts on chang      es that need\n",
              "3           hello greg how eit  her next tuesday\n",
              "4          hello greg how eith   er next tuesday"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ayf2_9Ripf6I"
      },
      "source": [
        "##Append all data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ry1M7mTuqg9g",
        "outputId": "948ae5ce-c82f-4385-bad7-a4e223febfae"
      },
      "source": [
        "final_data = pd.concat([data_short, data_long, data_wordbrk])\r\n",
        "final_data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 2218723 entries, 0 to 1230803\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Dtype \n",
            "---  ------  ----- \n",
            " 0   input   object\n",
            " 1   output  object\n",
            "dtypes: object(2)\n",
            "memory usage: 50.8+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De2m8U2HMk5Y"
      },
      "source": [
        "Since there is a possibility of duplicate items, we checked for the same and found there are many. So we remove the duplicate items from our data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWap8VuaKlc1",
        "outputId": "d3dbd0cb-5cbc-423c-d355-9f057e1046e3"
      },
      "source": [
        "final_data = final_data.drop_duplicates(ignore_index=True)\r\n",
        "final_data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 781268 entries, 0 to 781267\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   input   781268 non-null  object\n",
            " 1   output  781268 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 11.9+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NIfxgth2ES-O"
      },
      "source": [
        "# new_data.to_excel('cs2_long_sent.xlsx',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FBle2xGPICD"
      },
      "source": [
        "After preparing the data in required formats and appending the data and removing the duplicates, we got around 6lakh data points on which we will be training next word(s) prediction model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWKwzTSgd_rD"
      },
      "source": [
        "#Final Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "FG6QOn3CeDd3",
        "outputId": "cc5568e0-6256-4253-f362-c59f8d0d5ea3"
      },
      "source": [
        "new_data = final_data\r\n",
        "new_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>plus your thoughts</td>\n",
              "      <td>on any changes that</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>plus your thoughts on</td>\n",
              "      <td>any changes that</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>plus your thoughts on any</td>\n",
              "      <td>changes that</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>plus your thoughts on any changes</td>\n",
              "      <td>that need to be</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>plus your thoughts on any changes that</td>\n",
              "      <td>need to be</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    input               output\n",
              "0                      plus your thoughts  on any changes that\n",
              "1                   plus your thoughts on     any changes that\n",
              "2               plus your thoughts on any         changes that\n",
              "3       plus your thoughts on any changes      that need to be\n",
              "4  plus your thoughts on any changes that           need to be"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0rU1ra6OiDG"
      },
      "source": [
        "# import pickle\r\n",
        "# outfile = open('final_data_cs2_subject.pkl','wb')\r\n",
        "# pickle.dump(new_data,outfile)\r\n",
        "# outfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtBET9vUOzhv"
      },
      "source": [
        "import pickle\r\n",
        "infile = open('final_data_cs2_subject.pkl','rb')\r\n",
        "new_data = pickle.load(infile)\r\n",
        "infile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "MV3ePbt1e_jh",
        "outputId": "f4f9240b-13e4-4fdf-a449-a11c879b4c4f"
      },
      "source": [
        "'''Prepare the data in a format according to Encoder Decoder model'''\r\n",
        "\r\n",
        "new_data['decoder_input'] = '<start> ' + new_data['output'].astype(str)\r\n",
        "new_data['decoder_output'] = new_data['output'].astype(str) + ' <end>'\r\n",
        "new_data = new_data.drop(['output'], axis=1)\r\n",
        "new_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>decoder_input</th>\n",
              "      <th>decoder_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>plus your thoughts</td>\n",
              "      <td>&lt;start&gt; on any changes that</td>\n",
              "      <td>on any changes that &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>plus your thoughts on</td>\n",
              "      <td>&lt;start&gt; any changes that</td>\n",
              "      <td>any changes that &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>plus your thoughts on any</td>\n",
              "      <td>&lt;start&gt; changes that</td>\n",
              "      <td>changes that &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>plus your thoughts on any changes</td>\n",
              "      <td>&lt;start&gt; that need to be</td>\n",
              "      <td>that need to be &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>plus your thoughts on any changes that</td>\n",
              "      <td>&lt;start&gt; need to be</td>\n",
              "      <td>need to be &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    input  ...             decoder_output\n",
              "0                      plus your thoughts  ...  on any changes that <end>\n",
              "1                   plus your thoughts on  ...     any changes that <end>\n",
              "2               plus your thoughts on any  ...         changes that <end>\n",
              "3       plus your thoughts on any changes  ...      that need to be <end>\n",
              "4  plus your thoughts on any changes that  ...           need to be <end>\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbM7GKSw2hgd"
      },
      "source": [
        "max_len_enc = max([len(x.split()) for x in new_data.input])\r\n",
        "max_len_dec = max([len(x.split()) for x in new_data.decoder_input])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j16CR9eM4iS0",
        "outputId": "70195d01-b3b1-4978-c15b-b70aa50ed62a"
      },
      "source": [
        "max_len_enc, max_len_dec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnAwY2xUgpdl"
      },
      "source": [
        "We don't split the data into train and test because all the data we have should be put to use to generate better predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c3Z9fLpggh3",
        "outputId": "2186f120-4c0d-4f97-fb03-de42318f4b6d"
      },
      "source": [
        "'''Tokenize the encoder's vocab and decoder vocab.\r\n",
        "In decoder's tokenizer, we have to filter some characters to include <start>, <end> as unique tokens'''\r\n",
        "\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "\r\n",
        "tokenizer_encoder = Tokenizer(oov_token='out_of_vocab')\r\n",
        "tokenizer_encoder.fit_on_texts(new_data['input'].values)\r\n",
        "\r\n",
        "tokenizer_decoder = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\r\n",
        "tokenizer_decoder.fit_on_texts(np.append(new_data['decoder_input'].values,'<end>')) #to add <end> in the corpus\r\n",
        "\r\n",
        "vocab_size_enc = len(tokenizer_encoder.word_index)+1\r\n",
        "vocab_size_dec = len(tokenizer_decoder.word_index)+1\r\n",
        "\r\n",
        "print(\"Vocab sizes of encoder and decoder are \",vocab_size_enc,vocab_size_dec)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab sizes of encoder and decoder are  44893 34335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DOt6aczxk_W",
        "outputId": "2a077529-48bb-4d0e-bb35-8a149d02e297"
      },
      "source": [
        "tokenizer_decoder.word_index['<end>']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4nxuNg06KST"
      },
      "source": [
        "import pickle\r\n",
        "outfile = open('tokenizers_subject.pkl','wb')\r\n",
        "pickle.dump((tokenizer_encoder,tokenizer_decoder),outfile)\r\n",
        "outfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vm8Zq_s64vF",
        "outputId": "84b73507-518a-4d34-8e1e-8c5c5f5ba19c"
      },
      "source": [
        "'''change the sentences to tokens and then pad them to maximum length such that all inputs and outputs'''\r\n",
        "\r\n",
        "tokenzd_seq_enc = tokenizer_encoder.texts_to_sequences(new_data['input'].values)\r\n",
        "tokenzd_seq_dec_ip = tokenizer_decoder.texts_to_sequences(new_data['decoder_input'].values)\r\n",
        "tokenzd_seq_dec_op = tokenizer_decoder.texts_to_sequences(new_data['decoder_output'].values)\r\n",
        "\r\n",
        "enc_padded = pad_sequences(tokenzd_seq_enc, maxlen=max_len_enc, dtype='int32', padding='post')\r\n",
        "dec_ip_padded = pad_sequences(tokenzd_seq_dec_ip, maxlen=max_len_dec, dtype='int32', padding='post')\r\n",
        "dec_op_padded = pad_sequences(tokenzd_seq_dec_op, maxlen=max_len_dec, dtype='int32', padding='post')\r\n",
        "\r\n",
        "print(enc_padded.shape,dec_ip_padded.shape,dec_op_padded.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(781268, 16) (781268, 5) (781268, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD5cU3Ab7PaK"
      },
      "source": [
        "'''convert our data into tf.data format for easy and fast loading of batches'''\r\n",
        "\r\n",
        "BATCH_SIZE=1024\r\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(((enc_padded, dec_ip_padded),dec_op_padded))\r\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtMxWlVJnaML"
      },
      "source": [
        "'''Load pre trained word embeddings to encoder and decoder's embedding layers'''\r\n",
        "\r\n",
        "embeddings_index = dict()\r\n",
        "f = open('Translation/glove.6B.300d.txt')\r\n",
        "for line in f:\r\n",
        " values = line.split()\r\n",
        " word = values[0]\r\n",
        " coefs = np.asarray(values[1:], dtype='float32')\r\n",
        " embeddings_index[word] = coefs\r\n",
        "f.close()\r\n",
        "embedding_matrix_enc = np.random.normal(size=(vocab_size_enc, 300))\r\n",
        "for word, i in tokenizer_encoder.word_index.items():\r\n",
        " embedding_vector = embeddings_index.get(word)\r\n",
        " if embedding_vector is not None:\r\n",
        "  embedding_matrix_enc[i] = embedding_vector\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4YonCsmnboO"
      },
      "source": [
        "embeddings_index = dict()\r\n",
        "f = open('Translation/glove.6B.300d.txt')\r\n",
        "for line in f:\r\n",
        " values = line.split()\r\n",
        " word = values[0]\r\n",
        " coefs = np.asarray(values[1:], dtype='float32')\r\n",
        " embeddings_index[word] = coefs\r\n",
        "f.close()\r\n",
        "embedding_matrix_dec = np.random.normal(size=(vocab_size_dec, 300))\r\n",
        "for word, i in tokenizer_decoder.word_index.items():\r\n",
        " embedding_vector = embeddings_index.get(word)\r\n",
        " if embedding_vector is not None:\r\n",
        "  embedding_matrix_dec[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6bnGbKYjdFz"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\r\n",
        "\r\n",
        "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\r\n",
        "        \r\n",
        "        '''Initialize the embedding and LSTM layers that will be used in our encoder layer'''\r\n",
        "        \r\n",
        "        super().__init__()\r\n",
        "        self.lstm_size = lstm_size\r\n",
        "        self.embedding = Embedding(input_dim=inp_vocab_size, output_dim=embedding_size, input_length=input_length,\r\n",
        "                    mask_zero=True, name=\"embedding_layer_encoder\", weights=[embedding_matrix_enc], trainable=True)\r\n",
        "        # self.embedding = Embedding(input_dim=inp_vocab_size, output_dim=embedding_size, input_length=input_length,\r\n",
        "        #                            mask_zero=True, name=\"embedding_layer_encoder\")\r\n",
        "        self.lstm = LSTM(lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\r\n",
        "        self.lstm_output = 0\r\n",
        "        self.lstm_state_h=0\r\n",
        "        self.lstm_state_c=0\r\n",
        "\r\n",
        "\r\n",
        "    def call(self,input_sequence): \r\n",
        "        \r\n",
        "        '''\r\n",
        "        Takes encoder's input sequence and return encoder's lstm's output\r\n",
        "        '''\r\n",
        "        \r\n",
        "        input_embedd = self.embedding(input_sequence)\r\n",
        "        self.lstm_output, self.lstm_state_h,self.lstm_state_c = self.lstm(input_embedd)\r\n",
        "        return self.lstm_output, self.lstm_state_h,self.lstm_state_c\r\n",
        "\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gmsBNW6lrm9"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\r\n",
        "\r\n",
        "    def __init__(self,out_vocab_size,embedding_size,lstm_size,input_length):\r\n",
        "        \r\n",
        "        '''Initialize the embedding and LSTM layers that will be used in our decoder layer'''\r\n",
        "        \r\n",
        "        super().__init__()\r\n",
        "        # self.embedding = Embedding(input_dim=out_vocab_size, output_dim=embedding_size, input_length=input_length,\r\n",
        "        #                    mask_zero=True, name=\"embedding_layer_decoder\")\r\n",
        "        self.embedding = Embedding(input_dim=out_vocab_size, output_dim=embedding_size, input_length=input_length,\r\n",
        "                           mask_zero=True, name=\"embedding_layer_decoder\", weights=[embedding_matrix_dec], trainable=True)\r\n",
        "        self.lstm = LSTM(lstm_size, return_sequences=True, return_state=True, name=\"Decoder_LSTM\")\r\n",
        "        self.lstm_output = 0\r\n",
        "        self.lstm_state_h=0\r\n",
        "        self.lstm_state_c=0\r\n",
        "        \r\n",
        "\r\n",
        "\r\n",
        "    def call(self,input_sequence,initial_states):\r\n",
        "        \r\n",
        "        '''\r\n",
        "        Takes decoder's input for teacher forcing, encoder's final states as initial states for decoder's lstm and return decoder lstm's output\r\n",
        "        '''\r\n",
        "\r\n",
        "        input_embedd = self.embedding(input_sequence)\r\n",
        "        self.lstm_output, self.lstm_state_h,self.lstm_state_c = self.lstm(input_embedd, initial_state=initial_states)\r\n",
        "        return self.lstm_output, self.lstm_state_h,self.lstm_state_c\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-C58T5vYB5kv",
        "outputId": "4843bee8-394e-4f4f-a59b-15111ae04940"
      },
      "source": [
        "'''Create a functional model with the custom layers built above and train it with our data'''\r\n",
        "\r\n",
        "embed_dim = 300\r\n",
        "enc_input_length = max_len_enc\r\n",
        "dec_input_length = max_len_dec\r\n",
        "lstm_units = 512\r\n",
        "\r\n",
        "X_input1 = Input(shape=(max_len_enc,))\r\n",
        "X_input2 = Input(shape=(max_len_dec,))\r\n",
        "X_input3 = Input(shape=(max_len_dec,))\r\n",
        "\r\n",
        "encoder_output, encoder_h, encoder_c = Encoder(inp_vocab_size=vocab_size_enc, embedding_size=embed_dim,input_length=enc_input_length, lstm_size = lstm_units)(X_input1)\r\n",
        "decoder_output,_,_ = Decoder(out_vocab_size=vocab_size_dec, embedding_size=embed_dim,input_length=dec_input_length, lstm_size = lstm_units)(X_input2,initial_states=(encoder_h, encoder_c))\r\n",
        "output = Dense(vocab_size_dec, activation='softmax')(decoder_output)\r\n",
        "\r\n",
        "model = Model(inputs = [[X_input1,X_input2],X_input3], outputs = output)\r\n",
        "optimizer = tf.keras.optimizers.Adam()\r\n",
        "model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy')\r\n",
        "train_steps=new_data.shape[0]//BATCH_SIZE\r\n",
        "history = model.fit(train_dataset, steps_per_epoch=train_steps, epochs=30)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "762/762 [==============================] - 366s 466ms/step - loss: 4.5500\n",
            "Epoch 2/30\n",
            "762/762 [==============================] - 367s 482ms/step - loss: 3.4868\n",
            "Epoch 3/30\n",
            "762/762 [==============================] - 366s 481ms/step - loss: 2.9852\n",
            "Epoch 4/30\n",
            "762/762 [==============================] - 365s 479ms/step - loss: 2.6535\n",
            "Epoch 5/30\n",
            "762/762 [==============================] - 365s 479ms/step - loss: 2.3940\n",
            "Epoch 6/30\n",
            "762/762 [==============================] - 364s 478ms/step - loss: 2.1723\n",
            "Epoch 7/30\n",
            "762/762 [==============================] - 365s 479ms/step - loss: 1.9810\n",
            "Epoch 8/30\n",
            "762/762 [==============================] - 364s 478ms/step - loss: 1.8162\n",
            "Epoch 9/30\n",
            "762/762 [==============================] - 365s 479ms/step - loss: 1.6700\n",
            "Epoch 10/30\n",
            "762/762 [==============================] - 364s 478ms/step - loss: 1.5399\n",
            "Epoch 11/30\n",
            "762/762 [==============================] - 364s 478ms/step - loss: 1.4221\n",
            "Epoch 12/30\n",
            "762/762 [==============================] - 364s 478ms/step - loss: 1.3154\n",
            "Epoch 13/30\n",
            "762/762 [==============================] - 364s 478ms/step - loss: 1.2177\n",
            "Epoch 14/30\n",
            "762/762 [==============================] - 365s 478ms/step - loss: 1.1291\n",
            "Epoch 15/30\n",
            "762/762 [==============================] - 364s 478ms/step - loss: 1.0503\n",
            "Epoch 16/30\n",
            "762/762 [==============================] - 364s 477ms/step - loss: 0.9770\n",
            "Epoch 17/30\n",
            "762/762 [==============================] - 364s 478ms/step - loss: 0.9099\n",
            "Epoch 18/30\n",
            "762/762 [==============================] - 364s 478ms/step - loss: 0.8507\n",
            "Epoch 19/30\n",
            "762/762 [==============================] - 364s 478ms/step - loss: 0.7949\n",
            "Epoch 20/30\n",
            "762/762 [==============================] - 364s 478ms/step - loss: 0.7445\n",
            "Epoch 21/30\n",
            "762/762 [==============================] - 364s 478ms/step - loss: 0.6923\n",
            "Epoch 22/30\n",
            "762/762 [==============================] - 364s 478ms/step - loss: 0.6448\n",
            "Epoch 23/30\n",
            "762/762 [==============================] - 364s 478ms/step - loss: 0.6029\n",
            "Epoch 24/30\n",
            "762/762 [==============================] - 364s 478ms/step - loss: 0.5660\n",
            "Epoch 25/30\n",
            "762/762 [==============================] - 364s 477ms/step - loss: 0.5317\n",
            "Epoch 26/30\n",
            "762/762 [==============================] - 363s 477ms/step - loss: 0.5002\n",
            "Epoch 27/30\n",
            "762/762 [==============================] - 363s 477ms/step - loss: 0.4678\n",
            "Epoch 28/30\n",
            "762/762 [==============================] - 363s 476ms/step - loss: 0.4402\n",
            "Epoch 29/30\n",
            "762/762 [==============================] - 363s 476ms/step - loss: 0.4130\n",
            "Epoch 30/30\n",
            "762/762 [==============================] - 363s 476ms/step - loss: 0.3916\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_qOsPuyVjod",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecc06f16-d6d6-42ed-b140-1cdede002169"
      },
      "source": [
        "history = model.fit(train_dataset, steps_per_epoch=train_steps, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "762/762 [==============================] - 359s 471ms/step - loss: 0.2551\n",
            "Epoch 2/5\n",
            "762/762 [==============================] - 366s 480ms/step - loss: 0.2408\n",
            "Epoch 3/5\n",
            "762/762 [==============================] - 366s 481ms/step - loss: 0.2275\n",
            "Epoch 4/5\n",
            "762/762 [==============================] - 367s 482ms/step - loss: 0.2146\n",
            "Epoch 5/5\n",
            "762/762 [==============================] - 366s 481ms/step - loss: 0.2072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "DKmOcNQpKLXY",
        "outputId": "81e3718d-f5dd-41e9-d9ab-467e88910704"
      },
      "source": [
        "# Plot training & validation iou_score values\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "plt.figure(figsize=(10, 5))\r\n",
        "plt.plot(history.history['loss'])\r\n",
        "plt.title('Model loss')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.legend(['Train'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAFNCAYAAABIc7ibAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3Rc5Z3/8fdXvVu2ii3LRe64gQ3CYIpp4UcNJBuSQDaAQ5a2ECDJJhuym77Z9AIhS0ISaihJIAWSEAjVgMFGNjbghguyLTc1q1ld+v7+mLGRhWzLlkZ3NPq8zpkztzxz56t75sDHz33uc83dEREREZGBFRd0ASIiIiJDkUKYiIiISAAUwkREREQCoBAmIiIiEgCFMBEREZEAKISJiIiIBEAhTERinpkVmZmbWUIv2i40s5f7ehwRkUNRCBORqGJmpWbWama53ba/EQ5ARcFUJiLSvxTCRCQavQtctnfFzGYDacGVIyLS/xTCRCQaPQBc0WX9SuD+rg3MbJiZ3W9mFWa22cz+28ziwvvizeyHZlZpZpuAC3r47G/MbIeZbTOz/zGz+MMt0sxGm9njZlZtZhvM7Oou++aZWYmZ1ZnZLjP7cXh7ipn91syqzKzGzF43s5GH+90iMvgphIlINHoNyDKz6eFwdCnw225tfgYMAyYCpxEKbZ8K77sauBCYCxQDl3T77L1AOzA53Ob/Af92BHU+ApQBo8Pf8b9mdmZ4323Abe6eBUwCfh/efmW47rFADnAd0HQE3y0ig5xCmIhEq729YWcDa4Bte3d0CWa3unu9u5cCPwIuDzf5GPBTd9/q7tXAd7p8diRwPnCLu+9x93LgJ+Hj9ZqZjQVOBv7T3ZvdfQXwa97rwWsDJptZrrs3uPtrXbbnAJPdvcPdl7l73eF8t4jEBoUwEYlWDwCfABbS7VIkkAskApu7bNsMFIaXRwNbu+3ba3z4szvClwNrgF8C+YdZ32ig2t3rD1DDp4GpwNrwJccLu/xdTwGPmNl2M/u+mSUe5neLSAxQCBORqOTumwkN0D8f+GO33ZWEepTGd9k2jvd6y3YQutzXdd9eW4EWINfds8OvLHefeZglbgdGmFlmTzW4+3p3v4xQuPse8KiZpbt7m7t/w91nACcRumx6BSIy5CiEiUg0+zRwprvv6brR3TsIjbH6tpllmtl44HO8N27s98BNZjbGzIYDX+ry2R3A08CPzCzLzOLMbJKZnXY4hbn7VmAx8J3wYPujw/X+FsDMPmlmee7eCdSEP9ZpZmeY2ezwJdU6QmGy83C+W0Rig0KYiEQtd9/o7iUH2P0ZYA+wCXgZeAi4O7zvV4Qu+a0ElvP+nrQrgCRgNbAbeBQoOIISLwOKCPWK/Qn4mrs/E953LrDKzBoIDdK/1N2bgFHh76sjNNbtRUKXKEVkiDF3D7oGERERkSFHPWEiIiIiAVAIExEREQmAQpiIiIhIABTCRERERAKgECYiIiISgISgCzhcubm5XlRUFHQZIiIiIoe0bNmySnfP62nfoAthRUVFlJQcaNogERERkehhZpsPtE+XI0VEREQCoBAmIiIiEoCIhzAzizezN8zsrz3sSzaz35nZBjNbYmZFka5HREREJBoMxJiwmwk9Hy2rh32fBna7+2QzuxT4HvDxw/2CtrY2ysrKaG5u7lulg0BKSgpjxowhMTEx6FJERESkDyIawsxsDHAB8G3gcz00uRj4enj5UeAOMzM/zAdalpWVkZmZSVFREWbWl5KjmrtTVVVFWVkZEyZMCLocERER6YNIX478KfBFoPMA+wuBrQDu3g7UAjmH+yXNzc3k5OTEdAADMDNycnKGRI+fiIhIrItYCDOzC4Fyd1/WD8e6xsxKzKykoqLiQG36+jWDwlD5O0VERGJdJHvCTgYuMrNS4BHgTDP7bbc224CxAGaWAAwDqrofyN3vcvdidy/Oy+txvrNAVVVVMWfOHObMmcOoUaMoLCzct97a2nrQz5aUlHDTTTcNUKUiIiISLSI2JszdbwVuBTCz04H/cPdPdmv2OHAl8CpwCfDc4Y4HiwY5OTmsWLECgK9//etkZGTwH//xH/v2t7e3k5DQ86kuLi6muLh4QOoUERGR6DHg84SZ2TfN7KLw6m+AHDPbQGjg/pcGup7u2js6qWpooa3jQMPYemfhwoVcd911nHDCCXzxi19k6dKlzJ8/n7lz53LSSSexbt06AF544QUuvPBCIBTgrrrqKk4//XQmTpzI7bff3ue/R0RERKLTgDy2yN1fAF4IL3+1y/Zm4KMDUUNvtXU422qaMDNGpCf16VhlZWUsXryY+Ph46urqeOmll0hISOCZZ57hy1/+Mo899tj7PrN27Vqef/556uvrmTZtGtdff72moxAREYlBg+7ZkYfyjSdWsXp7XZ+O0djaQXwcJCfEAzBjdBZf++DMwz7ORz/6UeLjQ8eora3lyiuvZP369ZgZbW1tPX7mggsuIDk5meTkZPLz89m1axdjxow58j9GREREopIeW9SD+Dijo7PvQ9PS09P3LX/lK1/hjDPO4O233+aJJ5444DQTycnJ79URH097e3uf6xAREZHoE3M9YUfSY9VdTWMrW6obmZyXQVpy/5yi2tpaCgsLAbj33nv75ZgiIiIyeKknrAcZ4eBV39J/vVBf/OIXufXWW5k7d656t0RERAQbbDNCFBcXe0lJyX7b1qxZw/Tp0/v1ezaU1wPG5PyMfj1uf4jE3ysiIiL9z8yWuXuPc1GpJ+wAMpITaWrtoL2zb1NViIiIiPREIewAMlMScJw9zbp0KCIiIv1PIewAUpPiiTfr13FhIiIiInvFTAjr77FtcWZkpCTQ0Nze78fui2iqRURERI5cTISwlJQUqqqq+j2gZCQn0NrRSUt7dIwLc3eqqqpISUkJuhQRERHpo5iYJ2zMmDGUlZVRUVHRr8dt7+xkV20LLRWJZKREx6lKSUnRDPoiIiIxIDqSRR8lJiYyYcKEiBz75h++wLicNO791LyIHF9ERESGppi4HBlJC6bm8dqmKprbOoIuRURERGKIQtghLJiaS3NbJyWlu4MuRURERGKIQtghnDgxh6T4OBat79/xZiIiIjK0KYQdQlpSAsVFw1n0jkKYiIiI9B+FsF5YMDWPtTvr2VXXHHQpIiIiEiMUwnphwZQ8APWGiYiISL9RCOuF6QWZ5GUms2h9ZdCliIiISIxQCOsFM+PUKbm8tL6Cjk49NkhERET6TiGsl06bmkdNYxtvbasNuhQRERGJAQphvXTK5FzMNC5MRERE+odCWC/lZCQza/QwhTARERHpFwphh2HB1Fze2FpDXXNb0KWIiIjIIKcQdhgWTMmjo9NZvEF3SYqIiEjfRCyEmVmKmS01s5VmtsrMvtFDm4VmVmFmK8Kvf4tUPf3h2PHDyUhO4MV3FMJERESkbxIieOwW4Ex3bzCzROBlM3vS3V/r1u537n5jBOvoN4nxccyflMOidypwd8ws6JJERERkkIpYT5iHNIRXE8OvQT/J1oKpeWyraWJT5Z6gSxEREZFBLKJjwsws3sxWAOXAP919SQ/NPmJmb5rZo2Y2NpL19IfT9AgjERER6QcRDWHu3uHuc4AxwDwzm9WtyRNAkbsfDfwTuK+n45jZNWZWYmYlFRXBhp9xOWkU5aQphImIiEifDMjdke5eAzwPnNtte5W7t4RXfw0cd4DP3+Xuxe5enJeXF9lie2HB1Dxe21RNS3tH0KWIiIjIIBXJuyPzzCw7vJwKnA2s7damoMvqRcCaSNXTnxZMyaOprYOS0t1BlyIiIiKDVCR7wgqA583sTeB1QmPC/mpm3zSzi8JtbgpPX7ESuAlYGMF6+s38STkkxpsuSYqIiMgRM/fBdcNicXGxl5SUBF0Gl971KjWNbfzjlgVBlyIiIiJRysyWuXtxT/s0Y/4ROm1qPmt31lNe1xx0KSIiIjIIKYQdoQVTcwFYtF6z54uIiMjhUwg7QtNHZZGbkaxxYSIiInJEFMKOUFycsWBKLi9vqKSzc3CNqxMREZHgKYT1wYKpeVTvaeXt7bVBlyIiIiKDjEJYH5wyJTwuTJckRURE5DAphPVBbkYyswqzWPSOBueLiIjI4VEI66MFU/JYvmU39c1tQZciIiIig4hCWB8tmJpHe6ezeGNV0KWIiIjIIKIQ1kfHjhtOelK8xoWJiIjIYVEI66OkhDjmT8pl0foKBtsjoERERCQ4CmH94LSpuWytbqK0qjHoUkRERGSQUAjrBwum5gGaqkJERER6TyGsH4zPSWd8TppCmIiIiPSaQlg/WTAlj1c3VdHa3hl0KSIiIjIIKIT1kwVT82hs7aBkc3XQpYiIiMggoBDWT+ZPyiEhzjR7voiIiPSKQlg/yUhO4LjxwzUuTERERHpFIawfLZiax+oddVTUtwRdioiIiEQ5hbB+dFp4qoqX1qs3TERERA5OIawfzSjIIic9SZckRURE5JAUwvpRXJxx6pRcXlpfSWenHmEkIiIiB6YQ1s8WTM2jak8rq3fUBV2KiIiIRDGFsH526pTQuLAXdUlSREREDkIhrJ/lZSYzoyBL48JERETkoCIWwswsxcyWmtlKM1tlZt/ooU2ymf3OzDaY2RIzK4pUPQNpwdQ8lm3eTUNLe9CliIiISJSKZE9YC3Cmux8DzAHONbMTu7X5NLDb3ScDPwG+F8F6BsyCqbm0dzqLN2j2fBEREelZxEKYhzSEVxPDr+63DF4M3BdefhQ4y8wsUjUNlOLxI0hLimeR5gsTERGRA4jomDAzizezFUA58E93X9KtSSGwFcDd24FaIKeH41xjZiVmVlJREf3BJikhjlOn5PLXN3dQ09gadDkiIiIShSIawty9w93nAGOAeWY26wiPc5e7F7t7cV5eXv8WGSGfPXsq9c3tfP+pdUGXIiIiIlFoQO6OdPca4Hng3G67tgFjAcwsARgGVA1ETZF21KgsFp5UxMNLt7Bya03Q5YiIiEiUieTdkXlmlh1eTgXOBtZ2a/Y4cGV4+RLgOXePmanmb/nAFHIzkvnKX96mQzPoi4iISBeR7AkrAJ43szeB1wmNCfurmX3TzC4Kt/kNkGNmG4DPAV+KYD0DLjMlkf++YDpvltXyu9e3Bl2OiIiIRBEbbB1PxcXFXlJSEnQZvebuXHrXa6zbVc9znz+dEelJQZckIiIiA8TMlrl7cU/7NGN+hJkZ3/rQLOqb2/nBU92vxoqIiMhQpRA2AKaOzOSqk4t45PWtvLFld9DliIiISBRQCBsgN39gKvmZyXz1L6s0SF9EREQUwgZKRnIC/3XBDN7aVsvDS7cEXY6IiIgETCFsAH3w6ALmT8zhB0+to6qhJehyREREJEAKYQPIzPjmxTPZ09LO9/+hmfRFRESGMoWwATZlZCafPmUCvyvZynIN0hcRERmyFMIC8JmzpjAqK4Wv/Fkz6YuIiAxVCmEByEhO4L8vnM6q7XU8tGRz0OWIiIhIABTCAnLB7AJOnhwapF+pQfoiIiJDjkJYQMyMb1w0i6a2Dr73pGbSFxERGWoUwgI0OT+DT58ykT8sK2PZ5uqgyxEREZEBpBAWsM+cOZmCYSl85c+raO/oDLocERERGSAKYQFLT07gKxfOYPWOOh5copn0RUREhgqFsChw3qxRnDollx8+vY6Keg3SFxERGQoUwqKAmfH1i2bS3NbBdzVIX0REZEhQCIsSk/IyuPrUiTy2vIzXSzVIX0REJNYphEWRG8+czOhhoZn0NUhfREQktimERZG0pAS++sEZrN1ZzwOvaSZ9ERGRWKYQFmXOmTmKBVPz+PHT71Be3xx0OSIiIhIhCmFRJjST/kxa2jv57t81SF9ERCRWKYRFoQm56VyzYCJ/fGMbSzZVBV2OiIiIRIBCWJS64YzJFGan8tW/rKJNg/RFRERijkJYlEpNiuerH5zBul31fPtva3D3oEsSERGRfhSxEGZmY83seTNbbWarzOzmHtqcbma1ZrYi/PpqpOoZjM6ZOYp/O2UC9y4u5Tcvvxt0OSIiItKPEiJ47Hbg8+6+3MwygWVm9k93X92t3UvufmEE6xjUvnz+dLbVNPHtv6+hMDuV82YXBF2SiIiI9IOI9YS5+w53Xx5ergfWAIWR+r5YFRdn/OTjc5g7NptbfreCZZt3B12SiIiI9IMBGRNmZkXAXGBJD7vnm9lKM3vSzGYORD2DTUpiPL+6opiCYSlcfX8JpZV7gi5JRERE+ijiIczMMoDHgFvcva7b7uXAeHc/BvgZ8OcDHOMaMysxs5KKiorIFhylcjKSufdT83B3Ft6zlOo9rUGXJCIiIn0Q0RBmZomEAtiD7v7H7vvdvc7dG8LLfwcSzSy3h3Z3uXuxuxfn5eVFsuSoVpSbzq+vLGZ7bTNX319Cc1tH0CWJiIjIEYrk3ZEG/AZY4+4/PkCbUeF2mNm8cD2anfQgjhs/gp9+fA7Lt+zms79bQWenpq4QEREZjCLZE3YycDlwZpcpKM43s+vM7Lpwm0uAt81sJXA7cKlrQqxDOn92Af91/nSefHsn33lyTdDliIiIyBGI2BQV7v4yYIdocwdwR6RqiGWfPmUCW6sb+dVL7zJmeBpXnlQUdEkiIiJyGCI5T5hEkJnx1Q/OZFtNM994YhWjs1M5e8bIoMsSERGRXtJjiwax+Djj9svmMLtwGJ95eDkrt9YEXZKIiIj0kkLYIJeWlMCvrzyevMxkPn3f62ytbgy6JBEREekFhbAYkJeZzD0L59HWEZpDrKZRc4iJiIhEO4WwGDE5P4O7Lj+OrdVNXPPAMlraNYeYiIhINFMIiyEnTMzhBx89mqXvVvOFP7ypOcRERESimO6OjDEXzylkW00T3//HOsYMT+WL5x4VdEkiIiLSA4WwGHT9aZPYWt3E/72wkTHD0/jECeOCLklERES6UQiLQWbGty6eyc7aJr7yl7cpyE7hjGn5QZclIiIiXWhMWIxKiI/jjk8cy1GjMrnhweW8va026JJERESkC4WwGJaenMDdC48nOzWRK+5eqiAmIiISRRTCYtzIrBQevPpEUhPjueyu11iyqSrokkRERASFsCFhQm46f7huPnlZyVxx91KeX1sedEkiIiJDXq9CmJmlm1lceHmqmV1kZomRLU360+jsVP5w7XymjMzg6vtLeGLl9qBLEhERGdJ62xO2CEgxs0LgaeBy4N5IFSWRkZORzENXn8ix44Zz0yNv8NCSLUGXJCIiMmT1NoSZuzcC/wL8n7t/FJgZubIkUrJSErnvqnmcNjWPL//pLX7x4sagSxIRERmSeh3CzGw+8K/A38Lb4iNTkkRaalI8d11ezIVHF/DdJ9fyvX+sxV2POBIRERlIvZ2s9RbgVuBP7r7KzCYCz0euLIm0pIQ4brt0Lpkpidz5wkbqmtr41sWziIuzoEsTEREZEnoVwtz9ReBFgPAA/Up3vymShUnkxccZ//vhWWSlJvDLFzfR0NLODz96DInxumlWREQk0np7d+RDZpZlZunA28BqM/tCZEuTgWBm3HredL547jT+smI71z2wjOa2jqDLEhERiXm97fKY4e51wIeAJ4EJhO6QlBjx76dP5lsfmsVz68q58u6l1De3BV2SiIhITOttCEsMzwv2IeBxd28DNJI7xlx+4nh++vE5lGzezSd+tYTqPa1BlyQiIhKzehvCfgmUAunAIjMbD9RFqigJzsVzCrnr8uN4Z1c9H/vlq+ysbQ66JBERkZjUqxDm7re7e6G7n+8hm4EzIlybBOSs6SO576p57Kxt5pJfLKa0ck/QJYmIiMSc3g7MH2ZmPzazkvDrR4R6xSRGnTgxh4euPoE9Le1c8otXWbtTHZ8iIiL9qbeXI+8G6oGPhV91wD0H+4CZjTWz581stZmtMrObe2hjZna7mW0wszfN7NjD/QMkco4ek83vr51PfBx8/JevsXzL7qBLEhERiRm9DWGT3P1r7r4p/PoGMPEQn2kHPu/uM4ATgRvMbEa3NucBU8Kva4A7D6N2GQBTRmby6HUnkZ2WyCd/vYR/rt4VdEkiIiIxobchrMnMTtm7YmYnA00H+4C773D35eHlemANUNit2cXA/eFxZq8B2WZW0OvqZUCMHZHGH66dz6S8DK6+v4TbnllPZ6dujhUREemL3oaw64Cfm1mpmZUCdwDX9vZLzKwImAss6barENjaZb2M9wc1iQL5WSn84br5/MvcQn7yzDtc99tlmktMRESkD3p7d+RKdz8GOBo42t3nAmf25rNmlgE8BtwSnvD1sJnZNXtvCqioqDiSQ0g/SEmM50cfO4avXjiDZ9eW8+H/W8ymioagyxIRERmUDushge5e1yVIfe5Q7cMTvD4GPOjuf+yhyTZgbJf1MeFt3b/3LncvdvfivLy8wylZ+pmZcdUpE3jgqnlUNbRw8c9f4fm15UGXJSIiMuj05UnNdtCdZgb8Bljj7j8+QLPHgSvCd0meCNS6+44+1CQD5KTJuTx+4ymMGZ7GVfe9zs+f34C7xomJiIj0Vl9C2KH+j3syoedLnmlmK8Kv883sOjO7Ltzm78AmYAPwK+Df+1CPDLCxI9L44/UnceHRo/nBU+u44aHl7GlpD7osERGRQSHhYDvNrJ6ew5YBqQf7rLu/zCF6yzzUdXLDIWqUKJaaFM/tl85hdmEW331yLRvL93DXFccxPkdz+YqIiBzMQXvC3D3T3bN6eGW6+0EDnAwdZsY1CyZx76fmsbOumYvueIVF7+gGChERkYPpy+VIkf0smJrH4zeeTMGwFBbes5S7Fm3UODEREZEDUAiTfjU+J53Hrj+Jc2eN4n//vpabH1lBU2tH0GWJiIhEHYUw6XfpyQn8/BPH8oVzpvHEm9v5yJ2L2VrdGHRZIiIiUUUhTCLCzLjhjMncvfB4tu5u5KI7XmbxhsqgyxIREYkaCmESUWdMy+fxG08hJyOZy+9eym9eflfjxERERFAIkwEwITedP99wMmcdlc+3/rqamx9ZQW2TnjspIiJDm0KYDIiM5AR+8cnj+PzZU/nbWzs476eLeEWXJ0VEZAhTCJMBExdnfOasKTx2/UmkJMbzr79ewjeeWEVzm+6eFBGRoUchTAbcnLHZ/O2mU1l4UhH3vFLKBbe/xJtlNUGXJSIiMqAUwiQQqUnxfP2imTzw6XnsaengX/5vMbc9s562js6gSxMRERkQCmESqFOn5PHULQu44OgCfvLMO1xy52I2VjQEXZaIiEjEKYRJ4IalJXLbpXO54xNz2VzdyAW3v8R9i0vp7NRUFiIiErsUwiRqXHj0aJ66ZQEnTszha4+v4sp7lrKjtinoskRERCJCIUyiysisFO5ZeDzf/vAsSkp3c85PFvGXFds0wauIiMQchTCJOmbGv54wnidvPpXJ+Rnc/MgKbnz4DXbvaQ26NBERkX6jECZRqyg3nd9fO58vnDONp97eyTk/XcQL68qDLktERKRfKIRJVEuIj+OGMybz5xtOJjstkYX3vM5//ektGlvbgy5NRESkTxTCZFCYVTiMx288hatPncBDS7dw/m0v8fJ6PfZIREQGL4UwGTRSEuP5rwtm8PDVJ9Lp8MnfLOHfH1zGthrdQSkiIoOPQpgMOidOzOHpzy7g82dP5bm15Zz1oxe447n1egaliIgMKgphMiilJMbzmbOm8MznTuOMafn88Ol3OOeni3hu7a6gSxMREekVhTAZ1MYMT+POTx7H/VfNIz7OuOreEv7tvtfZXLUn6NJEREQOSiFMYsKCqXn84+YF3HreUSzeWMXZP1nEj59eR1OrLlGKiEh0UgiTmJGUEMe1p03iuc+fzrkzR3H7cxv4wI9f5B9v79SM+yIiEnUiFsLM7G4zKzeztw+w/3QzqzWzFeHXVyNViwwto4alcPtlc3nkmhPJSE7gut8u44q7l7KxoiHo0kRERPaJZE/YvcC5h2jzkrvPCb++GcFaZAg6cWIOf7vpFL72wRms2FLDuT9dxHeeXENDiyZ6FRGR4EUshLn7IqA6UscX6Y2E+Dg+dfIEnvuP07l4TiG/fHETZ/3oBR5fuV2XKEVEJFBBjwmbb2YrzexJM5sZcC0Sw/Iyk/nhR4/hsetPIi8zmZsefoNL73qNNTvqgi5NRESGqCBD2HJgvLsfA/wM+POBGprZNWZWYmYlFRUVA1agxJ7jxg/nLzecwrc/PIt1u+o5//aXuOWRN9hS1Rh0aSIiMsRYJC/JmFkR8Fd3n9WLtqVAsbsf9IGAxcXFXlJS0i/1ydBW09jKnS9u5N5XSunodC6bN47PnDmZ/KyUoEsTEZEYYWbL3L24p32B9YSZ2Sgzs/DyvHAtVUHVI0NPdloSt543nUVfPIOPHz+Wh5duYcEPnud7/1hLbWNb0OWJiEiMi1hPmJk9DJwO5AK7gK8BiQDu/gszuxG4HmgHmoDPufviQx1XPWESKaWVe/jJM+/w+MrtZCYncO1pk/jUyUWkJSUEXZqIiAxSB+sJi+jlyEhQCJNIW7Ojjh8+tY5n15aTm5HMTWdN5tLjx5GUEPR9LCIiMtgohIkcgZLSar7/j3UsLa1m7IhUPvuBqVw8p5D4OAu6NBERGSSickyYSLQrLhrB7649kXs+dTyZyYl87vcrOf+2l3h6lR6DJCIifacQJnIQZsYZ0/L562dO4WeXzaW1o5NrHljGv9y5mFc36j4SERE5cgphIr0QF2d88JjRPP3ZBXznX2azo6aZy371Gpf/ZglvldUGXZ6IiAxCGhMmcgSa2zp44NXN/N8LG9jd2MYZ0/K47rRJzJswgvDMKyIiIhqYLxIp9c1t3PtKKfcuLqVqTytzx2Vz3WmTOHv6SOI0gF9EZMhTCBOJsOa2Dv5QspVfLtpE2e4mJuWlc+1pk/jQnEJNbSEiMoQphIkMkPaOTv721g5+8eIm1uyoY1RWCv926gQunTeOjGRN+ioiMtQohIkMMHdn0fpK7nxhA69tqiYrJYEr5hex8OQicjOSgy5PREQGiEKYSIBWbK3hFy9s5KnVO0mKj+NjxWO5+tSJjMtJC7o0ERGJMIUwkSiwsaKBu17cxB/fKKOj07ng6NFcd9pEZo4eFnRpIiISIQphIlFkV10zd7/8Lg8u2UJDSzsLpuZx3QzaODQAABW3SURBVGkTmT8xR9NbiIjEGIUwkShU29TGb1/bzD2vlFLZ0MLswmFcPn88Fx0zmpTE+KDLExGRfqAQJhLFmts6eGx5Gfe+Usr68gay0xL5ePFYPnnieMaO0LgxEZHBTCFMZBBwd17bVM0Dr5Xy1KpddLpzxrR8Lp8/ntOm5GnyVxGRQUghTGSQ2VHbxMNLtvDQ0q1UNrQwPieNy08cz0ePG8uwtMSgyxMRkV5SCBMZpFrbO/nHqp088Gopr5fuJiUxjouPKeTy+eOZVai7KkVEop1CmEgMWL29jgdeK+XPb2ynqa2DY8dlc8X8Is6bPYrkBA3kFxGJRgphIjGktqmNR5eV8dvXNvNu5R5yM5K49PhxfOKEcYzOTg26PBER6UIhTCQGdXY6L2+o5P5XS3l2bTlxZnxgej4fP34sC6bkkRCvB4eLiATtYCFMTxQWGaTi4owFU/NYMDWPrdWNPLhkC78v2cpTq3aRl5nMh+cW8pFjxzBtVGbQpYqISA/UEyYSQ1rbO3lhXTmPLivjubXltHc6swuHcclxY7jomNEMT08KukQRkSFFlyNFhqCqhhYeX7mdR5eVsWp7HYnxxllHjeSS48Zw2rQ8EnW5UkQk4hTCRIa41dvreGx5GX9ZsY3KhlZyM5K4eE4hlxw3hukFWUGXJyISsxTCRASAto5OXlxXwaPLynh27S7aOpyZo7P4yLFjuHjOaHIykoMuUUQkpgQSwszsbuBCoNzdZ/Ww34DbgPOBRmChuy8/1HEVwkT6R/WeVp4IX658a1stCXHGmUfl85HjxnDGtHySEnS5UkSkr4IKYQuABuD+A4Sw84HPEAphJwC3ufsJhzquQphI/1u7s47HlpXxpze2U9nQQnZaIufMGMUFRxdw0qQcTXchInKEArscaWZFwF8PEMJ+Cbzg7g+H19cBp7v7joMdUyFMJHLaOzpZtL6CJ1bu4J+rd9HQ0s7wtETOnVXAhUcXcMKEEQpkIiKHIVrnCSsEtnZZLwtve18IM7NrgGsAxo0bNyDFiQxFCfFxnHnUSM48aiTNbR28+E4Ff3tzB39ZsY2Hl24hJz2Jc2eFeshOmJBDfJwFXbKIyKA1KCZrdfe7gLsg1BMWcDkiQ0JKYjznzBzFOTNH0dzWwQvrynnizR38cfk2HlyyhdyMZM6fPYoLZhdQXDRCgUxE5DAFGcK2AWO7rI8JbxORKJOSGM+5swo4d1YBja3tPL+2gr+9tZ3fl2zl/lc3k5+ZzPmzQ5csjx03nDgFMhGRQwoyhD0O3GhmjxAamF97qPFgIhK8tKQELji6gAuOLmBPSzvPri3nb29u56GlW7h3cSmjslI4f3Zo/9yx2QpkIiIHEMm7Ix8GTgdygV3A14BEAHf/RXiKijuAcwlNUfEpdz/kiHsNzBeJTvXNbTy3tpwnVu5g0TsVtHZ0kpuRzFlH5XPW9HxOmZJLWtKgGAEhItJvNFmriAyouuY2nltTzjNrdvHiugrqW9pJTojj5Mm5nDU9n7OOGsmoYSlBlykiEnEKYSISmNb2Tl4vreaZNbt4Zs0utlY3ATCrMIsPTB/JB6aPZOboLEKd4yIisUUhTESigruzvryBZ9bs4tk15Szfsht3GJWVwlnT8/nA9JHMn5RDSmJ80KWKiPQLhTARiUqVDS08v7acZ9eUs2h9BY2tHaQmxnPKlFzOnj6SM47KJy9Tz7MUkcFLIUxEol5zWwevbari2TXlPLtmF9trmzGDWaOHcdLkHE6elMvxRSNITVIvmYgMHgphIjKouDurd9Tx7JpyXl5fyRtbd9PW4STFxzF3XDYnTcrl5Mk5HDM2m0Q9RklEophCmIgMao2t7Sx9t5rFG6tYvLGSVdvrcIe0pHjmTRjByZNyOWlyDtNHZWleMhGJKtH67EgRkV5JS0rg9Gn5nD4tH4Dde1p5bVMVizdW8crGSl5YtwaA4WmJzJ+UE+4py6UoJ013XYpI1FIIE5FBZ3h6EufNLuC82QUA7Kht4tWNVbyyIdRT9ve3dgIwelgK88OXLk+YmENhdmqQZYuI7EeXI0Ukprg771bu2Xfp8tWNVexubAOgMDuVeRNG7HtNzE1XT5mIRJTGhInIkNXZ6azZWcfr71aztLSape9WU9nQCkBuRhLzJozg+KJQKDtqVBbxGlMmIv1IIUxEJGxvT9nSd0OBbMm71WyrCc3in5mSsC+QHV80gtmFw0hK0N2XInLkNDBfRCTMzJiYl8HEvAwunTcOgLLdjbwe7iVb+m41z60tByAlMY5jxw3fd/lyzthsPYRcRPqN/msiIkPemOFpjBmexofnjgGgor6FktJQL9nSd6u57dn1uEN8nDFtZCZzxmUzZ2w2x47LZmJuhqbFEJEjosuRIiKHUNvUxrLN1SzfXMOKrTWs3FpDfUs7ELqEecyYUCibMzabOeOyyc3Qo5ZEJESXI0VE+mBYaiJnHjWSM48aCYQG+2+qbOCNLTW8sbWGFVtquPPFjXR0hv5RO3ZEKnPGDt8XzGaOztJDyUXkfRTCREQOU1ycMTk/k8n5mXy0eCwQmtX/7W11rNi6mxVbaygpreaJldsBSIw3ZhRk7espmzl6GBNz00nQI5dEhjRdjhQRiZBddc28sSV0CXPF1t28WVZLY2sHAMkJcUwblcmMgixmjM5iRkEWRxVkkZGsfxuLxBJNUSEiEgU6Op0N5Q2s3lHL6u11rN5Rx+rtdfsmkwUoyknbF8pC78MYmZWsSWVFBimNCRMRiQLxcca0UZlMG5XJh+eGtrk7O+uaQ6EsHMxWba/b9+glgBHpSfv1mM0YnaXLmSIxQCFMRCRAZkbBsFQKhqVy1vSR+7bXN7exdmf9fuHs3ldKae3oBCApIY6pIzM4alQWR43KDL0XZOrOTJFBRCFMRCQKZaYkcnxRaOb+vdo6OtlUsYdV22tZu7OeNTvqePGdCh5dVravTW5GMtMLMvcLZpPzM0hO0N2ZItFGIUxEZJBIjI/bdzmzq8qGFtaFQ9nanfWs3VnHfa9uprU91GuWEGdMzEvfF8qmh99HZaVorJlIgBTCREQGudyMZHInJ3Py5Nx929o7Oimt2sOaHaFQtnZHPcs27+bx8LQZEJr/bHJ+BpPy0pmUlxF65WcwdniqxpuJDADdHSkiMoTUNrWxLtxbtnZnPRvLG9hYsYfKhpZ9bZLi4yjKTesSzEIhbWJehqbQEDlMgd0daWbnArcB8cCv3f273fYvBH4AbAtvusPdfx3JmkREhrJhqYn7HkjeVW1jGxsrG/aFsg3lDazbWc/Tq3ftexIAQMGwlHA4S2dSfiikTc7PID9T02iIHK6IhTAziwd+DpwNlAGvm9nj7r66W9PfufuNkapDREQObVhaIseOG86x44bvt721vZMt1XvYUL6HjRUN4dceHlu+jYbw8zMh9AzNyfkZTMnPCL+HbggozE7VA85FDiCSPWHzgA3uvgnAzB4BLga6hzAREYlSSQlx+x7R1JW7U17fwobyUDBbv6uBDeUNPLe2gt+XvHe3ZmpiPJPy0/eFsr2v8SPSNO5MhrxIhrBCYGuX9TLghB7afcTMFgDvAJ919609tBERkShiZozMSmFkVsp+NwQA1DS2sqG8gfXl4XBW0cCSTVX86Y1t+9okxccxITd9v2A2ITed8TlpZKYkDvSfIxKIoEdYPgE87O4tZnYtcB9wZvdGZnYNcA3AuHHjBrZCERE5LNlpSRQXjaC4aP9xZw0t7WzcG87KQzcFvL29lr+/vYOu94jlZiRRlJPO+Jx0JuSmhd8V0CT2ROzuSDObD3zd3c8Jr98K4O7fOUD7eKDa3Ycd7Li6O1JEJLY0t3XwbuUeSiv3UFrVGH4PvXbVtezXNjcjifE56RTlpFOUk0ZRbng5VwFNolNQd0e+DkwxswmE7n68FPhEt8IK3H1HePUiYE0E6xERkSiUkhjP9IIsphdkvW9fY2s7m6sa2Vy1h3cr977v4ZUNlTy2vHm/tjnpSYwdkUbh8FTGDE9lTHZqeDmNwuxU0jW9hkSZiP0i3b3dzG4EniI0RcXd7r7KzL4JlLj748BNZnYR0A5UAwsjVY+IiAw+aUkJBw1oW6ob9+tB27q7kVXbavnnql37nrO5V3ZaImOGp1KY/V4wey+wpZGVmqBpNmRAabJWERGJOZ2dTkVDC2W7m9hW00TZ7ka27VtuYtvuJpraOvb7TEZywr6QNmpYCqOzUxmVlUJBdkr4IesppCTqGZxyeAKbrFVERCQIcXHv3b153Pjh79vv7uxubGPb7nBAC4ezvaFt+Zbd7G5se9/nhqclMmpYKqOHpSioSZ8phImIyJBjZoxIT2JEehKzx/R8P1hzWwc7apvZUdvEztrm/Za31zTzxtYaqve0vu9ze4PaqKxkRmalkJ+VwsisZEZmpoSDYTI5GcnEaxLbIU8hTEREpAcpifFMyA1Nj3EgzW0d+wW0fe81zeyqb+bt7XVUNrTQfeRPnEFeZjikZSaHglpmOKxlpZAffh+RlqQnDsQwhTAREZEjlJIYH5om4yBBrb2jk6o9reyqa2ZXXQu76pop37tc38y2mmbe2FJDVQ+9aglxRk5GErkZyfteeZnJ5GYkkZeZTF5GMrmZoe3ZqYkKbIOMQpiIiEgEJcTH7RufdjCt7Z1UNHQLaXXNVDa0UNnQSmVDC+/sqqeyoYW2jvffVNc9sOVl7g1uCmzRSiFMREQkCiQlxIWmzchOPWg7d6euqZ2KhmYq6kPhrKK+JRzW9i63HjKwjUhP6hLUksnNTCJvv/AWCnDDdUk0YhTCREREBhEzY1haIsPSEpmcf/C27k5tU1s4nLVS0dBCZZfAVtnQSkX9wXvY4uOMnPRQD9vw9ESy05IYnpbI8LQkstOSGLFvW2h7dloSWSmac603FMJERERilJmRHQ5LvQlsoR62/XvWKhtaqAz3uO1ubGVHTR27G1upaWp73w0He8XH2b5A1vV9b3ALbUsM1xbaPiw1cchN76EQJiIiIt162DIO2b6z06lrbmN3Yxu7G1vZvaeV3Y1t1DS2htb3Lu9pY2t1I2+Vhdq1tHce8JipifH7wtl+QS01HNS6BLbMlAQykkOv9OQEkhLi+vN0DAiFMBERETlscXHv9bJN4MB3h3bX1NpBTVMonNWEe9R2N7ZSEw5tNY1t+wLcO7sa9m1r7zz4E36SEuLITE4gI+W9YLZ3fd9yt/UJeekcNer9j8QaKAphIiIiMmBSk+JJTUqlYNjBb0Doyt1paGkPB7U2appa2dPSTn1zOw0t7aHllnYamkPLDeF9u+qb2Vjx3nr3XrhPnjiO//nQ7P7+E3tNIUxERESimpmRmZJIZkoiY0cc+XHaOjr3hbc9re1kJAcbgxTCREREZEhIjI/bdwk1Ggy+UWwiIiIiMUAhTERERCQACmEiIiIiAVAIExEREQmAQpiIiIhIABTCRERERAKgECYiIiISAIUwERERkQAohImIiIgEQCFMREREJADmfvCnkkcbM6sANg/AV+UClQPwPUORzm3k6NxGls5v5OjcRpbOb+Qc6tyOd/e8nnYMuhA2UMysxN2Lg64jFuncRo7ObWTp/EaOzm1k6fxGTl/OrS5HioiIiARAIUxEREQkAAphB3ZX0AXEMJ3byNG5jSyd38jRuY0snd/IOeJzqzFhIiIiIgFQT5iIiIhIABTCujGzc81snZltMLMvBV1PrDGzUjN7y8xWmFlJ0PUMZmZ2t5mVm9nbXbaNMLN/mtn68PvwIGsczA5wfr9uZtvCv98VZnZ+kDUOVmY21syeN7PVZrbKzG4Ob9fvt48Ocm712+0HZpZiZkvNbGX4/H4jvH2CmS0JZ4ffmVlSr46ny5HvMbN44B3gbKAMeB24zN1XB1pYDDGzUqDY3TVfTR+Z2QKgAbjf3WeFt30fqHb374b/ETHc3f8zyDoHqwOc368DDe7+wyBrG+zMrAAocPflZpYJLAM+BCxEv98+Oci5/Rj67faZmRmQ7u4NZpYIvAzcDHwO+KO7P2JmvwBWuvudhzqeesL2Nw/Y4O6b3L0VeAS4OOCaRHrk7ouA6m6bLwbuCy/fR+g/vnIEDnB+pR+4+w53Xx5ergfWAIXo99tnBzm30g88pCG8mhh+OXAm8Gh4e69/uwph+ysEtnZZL0M/3v7mwNNmtszMrgm6mBg00t13hJd3AiODLCZG3Whmb4YvV+pyWR+ZWREwF1iCfr/9qtu5Bf12+4WZxZvZCqAc+CewEahx9/Zwk15nB4UwGWinuPuxwHnADeFLPhIBHhproPEG/etOYBIwB9gB/CjYcgY3M8sAHgNucfe6rvv0++2bHs6tfrv9xN073H0OMIbQFbSjjvRYCmH72waM7bI+JrxN+om7bwu/lwN/IvQDlv6zKzwmZO/YkPKA64kp7r4r/B/gTuBX6Pd7xMLjaR4DHnT3P4Y36/fbD3o6t/rt9j93rwGeB+YD2WaWEN7V6+ygELa/14Ep4bsckoBLgccDrilmmFl6eKAoZpYO/D/g7YN/Sg7T48CV4eUrgb8EWEvM2RsQwj6Mfr9HJDy4+TfAGnf/cZdd+v320YHOrX67/cPM8swsO7ycSuhGvjWEwtgl4Wa9/u3q7shuwrft/hSIB+52928HXFLMMLOJhHq/ABKAh3R+j5yZPQycDuQCu4CvAX8Gfg+MAzYDH3N3DS4/Agc4v6cTupzjQClwbZcxTNJLZnYK8BLwFtAZ3vxlQmOX9Pvtg4Oc28vQb7fPzOxoQgPv4wl1ZP3e3b8Z/v/bI8AI4A3gk+7ecsjjKYSJiIiIDDxdjhQREREJgEKYiIiISAAUwkREREQCoBAmIiIiEgCFMBEREZEAKISJSEwxsw4zW9Hl9aV+PHaRmWl+JRHpFwmHbiIiMqg0hR8pIiIS1dQTJiJDgpmVmtn3zewtM1tqZpPD24vM7Lnwg42fNbNx4e0jzexPZrYy/DopfKh4M/uVma0ys6fDs2aLiBw2hTARiTWp3S5HfrzLvlp3nw3cQejJGAA/A+5z96OBB4Hbw9tvB15092OAY4FV4e1TgJ+7+0ygBvhIhP8eEYlRmjFfRGKKmTW4e0YP20uBM919U/gBxzvdPcfMKoECd28Lb9/h7rlmVgGM6froETMrAv7p7lPC6/8JJLr7/0T+LxORWKOeMBEZSvwAy4ej6/PgOtDYWhE5QgphIjKUfLzL+6vh5cXApeHlfyX08GOAZ4HrAcws3syGDVSRIjI06F9wIhJrUs1sRZf1f7j73mkqhpvZm4R6sy4Lb/sMcI+ZfQGoAD4V3n4zcJeZfZpQj9f1wI6IVy8iQ4bGhInIkBAeE1bs7pVB1yIiArocKSIiIhII9YSJiIiIBEA9YSIiIiIBUAgTERERCYBCmIiIiEgAFMJEREREAqAQJiIiIhIAhTARERGRAPx/XvOCnV4mMzIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zzPYBUMcBZI",
        "outputId": "37c37b3a-9e7e-49a3-a94a-1b32eaf513a9"
      },
      "source": [
        "model.save('final_enc_dec_wthsubj_upd')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_encoder_layer_call_fn, embedding_layer_encoder_layer_call_and_return_conditional_losses, embedding_layer_decoder_layer_call_fn, embedding_layer_decoder_layer_call_and_return_conditional_losses, embedding_layer_encoder_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as embedding_layer_encoder_layer_call_fn, embedding_layer_encoder_layer_call_and_return_conditional_losses, embedding_layer_decoder_layer_call_fn, embedding_layer_decoder_layer_call_and_return_conditional_losses, embedding_layer_encoder_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: final_enc_dec_wthsubj_upd/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: final_enc_dec_wthsubj_upd/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaZH4ftQcKrj"
      },
      "source": [
        "loaded_model = tf.keras.models.load_model('final_enc_dec_wthsubj_upd')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TugBBBcJf5j5",
        "outputId": "a1faf266-c5ff-4552-9cb0-9f05409ddbec"
      },
      "source": [
        "loaded_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 16)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder (Encoder)               ((None, 16, 512), (N 15132924    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Decoder)               ((None, 5, 512), (No 11965524    input_2[0][0]                    \n",
            "                                                                 encoder[0][1]                    \n",
            "                                                                 encoder[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 5)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 5, 34335)     17613855    decoder[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 44,712,303\n",
            "Trainable params: 44,712,303\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKDolL3AmYkX"
      },
      "source": [
        "def predict(input_sentence,model):\r\n",
        "\r\n",
        "  '''\r\n",
        "  Given an input sentence, we need to predict the next words.\r\n",
        "  Tokenize and pad the input sentence,\r\n",
        "  Pass it to encoder's embedding layer and its output to encoder's LSTM layer.\r\n",
        "  Pass its final states hidden and cell states as inputs to decoder's LSTM\r\n",
        "  Before that, initialize <start> word and pass it to decoders embedding layer and then to LSTM layer,\r\n",
        "  We run a loop till we get <end> word.\r\n",
        "  We give predicted word at decoder's current step as input to its next step.\r\n",
        "  '''\r\n",
        "  \r\n",
        "  encoder_test_tokens = tokenizer_encoder.texts_to_sequences([input_sentence])\r\n",
        "  padded_encoder_input = pad_sequences(encoder_test_tokens, maxlen=16, dtype='float32', padding='post')\r\n",
        "  encoder = model.layers[2]\r\n",
        "  encoder_op, enc_h, enc_c = encoder(padded_encoder_input)\r\n",
        "  decoder = model.layers[3]\r\n",
        "  index_of_start = np.array(tokenizer_decoder.word_index['<start>']).reshape(1,1)\r\n",
        "  states=(enc_h, enc_c)\r\n",
        "  dense = model.layers[5]\r\n",
        "  pred=0\r\n",
        "  sentence = []\r\n",
        "  while pred!=tokenizer_decoder.word_index['<end>']:\r\n",
        "    dec_emb= decoder.embedding(index_of_start)\r\n",
        "    predicted_out,state_h,state_c=decoder.lstm(dec_emb,states)\r\n",
        "    pred = np.argmax(dense(predicted_out))\r\n",
        "    word = [k for k in tokenizer_decoder.word_index if tokenizer_decoder.word_index[k]==pred][0]\r\n",
        "    sentence.append(word)\r\n",
        "    states= (state_h, state_c)\r\n",
        "    index_of_start = np.array(pred).reshape(1,1)\r\n",
        "  return ' '.join(sentence[:-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNyBXCAyM1mO"
      },
      "source": [
        "Now we will separate out sentences where predictions are bad and analyse them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0Bdmc7KMxHb",
        "outputId": "6dadb815-bd4a-4570-a18d-2ffc59b071e8"
      },
      "source": [
        "import numpy as np\r\n",
        "sample = new_data.sample(100000,random_state=42)\r\n",
        "import nltk.translate.bleu_score as bleu\r\n",
        "from tqdm import tqdm\r\n",
        "incorrect_predictions=[]\r\n",
        "for i in tqdm(sample.index):\r\n",
        "  predicted = predict(new_data.loc[i]['input'],loaded_model)\r\n",
        "  predicted_sent = predicted.split()\r\n",
        "  original = [x for x in new_data.loc[i]['decoder_input'].split() if x!='<start>']\r\n",
        "  if bleu.sentence_bleu([original],predicted_sent)<0.2:\r\n",
        "    incorrect_predictions.append((new_data.loc[i]['input'],' '.join(original),predicted))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [1:46:14<00:00, 15.69it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiswAJGn2lC-"
      },
      "source": [
        "# import pickle\r\n",
        "# outfile = open('incorrect_preds.pkl','wb')\r\n",
        "# pickle.dump(incorrect_predictions,outfile)\r\n",
        "# outfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWc1BpR0V6Vr"
      },
      "source": [
        "import pickle\r\n",
        "infile = open('incorrect_preds.pkl','rb')\r\n",
        "incorrect_predictions = pickle.load(infile)\r\n",
        "infile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u47xkswLvgNU",
        "outputId": "1d059dbd-6976-4116-8f27-28571319a82f"
      },
      "source": [
        "for i in range(len(incorrect_predictions[:20])):\r\n",
        "  print(incorrect_predictions[i][0],\"_\",incorrect_predictions[i][1],'_',incorrect_predictions[i][2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "price processes for ng i should examine other contracts behavior beyond prompt _ month as _ ly worse the\n",
            "did i call it or i am looking _ damn good at bux _ forward to\n",
            "stca forward ob position the stca desk will be _ short mw _ under on peak\n",
            "ene friday report please open as read only _ and do _ thing good\n",
            "martin gas sales could someone please call _ tom redd at _ me for lunch\n",
            "txu fuel deal please verify the price for _ txu fuel _ ward rate for\n",
            "pos.mgr please run it again _ and let me _ st to greg\n",
            "pge sale agreement terminated to read the press release click on _ the following link _ to submit your\n",
            "phone number country code _ city code telephone _ mark taylor will\n",
            "nd request updates for september did i or did i _ not already _ send them\n",
            "are you guys coming to regards mike do you yahoo make _ a great connection at _ welcome online with\n",
            "current d o report this report is being _ provided as a _ forwarded by david\n",
            "oa improvements i believe a large improvement _ can be _ ns are for\n",
            "commodity quote web site asp symbols ng options ngu _ type optfut _ kets fmt o\n",
            "australian approvals list of counterparties _ just mirror the approvals _ ations are both\n",
            "centana hey charlie fyi joe parks is _ going to be managing _ ing for gas\n",
            "fw big commitment i do not think that _ they will _ way is\n",
            "accomplishments i have given you little more than _ you have asked _ ks for your\n",
            "it is all good i _ was looking _ enjoyed talking\n",
            "mapp loss matrix save the book _ mark for future _ ed click here\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1nD1YT3vDRE",
        "outputId": "9314ff2b-9406-4015-a32c-d16c73cf465a"
      },
      "source": [
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\r\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "sample = new_data.sample(1000)\r\n",
        "import nltk.translate.bleu_score as bleu\r\n",
        "\r\n",
        "blue_scores=[]\r\n",
        "for n,i in enumerate(sample.index):\r\n",
        "  predicted = predict(new_data.loc[i]['input'],loaded_model).split()\r\n",
        "  original = [x for x in new_data.loc[i]['decoder_input'].split() if x!='<start>']\r\n",
        "  blue_scores.append(bleu.sentence_bleu([original],predicted))\r\n",
        "  if n in range(30):\r\n",
        "    print('-- ip:',new_data.loc[i]['input'],'-- prd: ' ,' '.join(predicted))\r\n",
        "    print('-- ip:',new_data.loc[i]['input'],'-- orgnl: ' ,' '.join(original),'\\n')\r\n",
        "\r\n",
        "np.mean(blue_scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- ip: london research please join us in congratulating steve -- prd:  on their new\n",
            "-- ip: london research please join us in congratulating steve -- orgnl:  on his new responsibilities \n",
            "\n",
            "-- ip: options we can send you -- prd:  where it is\n",
            "-- ip: options we can send you -- orgnl:  a list of \n",
            "\n",
            "-- ip: sample master agreement let me know if there anyth -- prd:  ing else that\n",
            "-- ip: sample master agreement let me know if there anyth -- orgnl:  ing else that \n",
            "\n",
            "-- ip: conference call rescheduled the conference previo -- prd:  usly scheduled for\n",
            "-- ip: conference call rescheduled the conference previo -- orgnl:  usly scheduled for \n",
            "\n",
            "-- ip: can you kill this deal or zero out -- prd:  the side\n",
            "-- ip: can you kill this deal or zero out -- orgnl:  the volumes \n",
            "\n",
            "-- ip: sempra confirmation examples mark see con -- prd:  firmation examples for\n",
            "-- ip: sempra confirmation examples mark see con -- orgnl:  firmation examples for \n",
            "\n",
            "-- ip: working today shoot me a reply yo this message -- prd:  ing if you\n",
            "-- ip: working today shoot me a reply yo this message -- orgnl:  if all is \n",
            "\n",
            "-- ip: statoil assignment to j. aron the attorney ste -- prd:  ve bunkin whom\n",
            "-- ip: statoil assignment to j. aron the attorney ste -- orgnl:  ve bunkin whom \n",
            "\n",
            "-- ip: price forecast for commodities wales stacey orig -- prd:  ination transaction support\n",
            "-- ip: price forecast for commodities wales stacey orig -- orgnl:  ination transaction support \n",
            "\n",
            "-- ip: east curves i have saved them -- prd:  to o dropbox\n",
            "-- ip: east curves i have saved them -- orgnl:  out to o \n",
            "\n",
            "-- ip: prices for clark pud we will be working with john griffith on -- prd:  issues in sections\n",
            "-- ip: prices for clark pud we will be working with john griffith on -- orgnl:  the structured \n",
            "\n",
            "-- ip: governor davis attached please find dav -- prd:  is press release\n",
            "-- ip: governor davis attached please find dav -- orgnl:  is press release \n",
            "\n",
            "-- ip: jedi spv i equity swap the transaction is for shares -- prd:  and a\n",
            "-- ip: jedi spv i equity swap the transaction is for shares -- orgnl:  and a \n",
            "\n",
            "-- ip: el paso joel ephross on -- prd:  economic interests\n",
            "-- ip: el paso joel ephross on -- orgnl:  issues reacquiring economic interests \n",
            "\n",
            "-- ip: holiday soiree in the th com r iid -- prd:  li ic fun\n",
            "-- ip: holiday soiree in the th com r iid -- orgnl:  ymidjqqkteiekbvqrkae li ic still \n",
            "\n",
            "-- ip: revised compression agreement attached is a clean red -- prd:  line version with\n",
            "-- ip: revised compression agreement attached is a clean red -- orgnl:  line version of \n",
            "\n",
            "-- ip: lsu cultivation dinner thanks a million dil -- prd:  lingham recruiter corina\n",
            "-- ip: lsu cultivation dinner thanks a million dil -- orgnl:  lingham recruiter corina \n",
            "\n",
            "-- ip: accomplishments i had not thought integra -- prd:  ting my goals\n",
            "-- ip: accomplishments i had not thought integra -- orgnl:  ting my goals \n",
            "\n",
            "-- ip: data for training program let me know -- prd:  if you have any\n",
            "-- ip: data for training program let me know -- orgnl:  if you need anything \n",
            "\n",
            "-- ip: stipend to uc berkeley policy i will participat -- prd:  ing in the\n",
            "-- ip: stipend to uc berkeley policy i will participat -- orgnl:  ing in the \n",
            "\n",
            "-- ip: rp data response to socal this was inadvertently left off from prev -- prd:  ious e mail\n",
            "-- ip: rp data response to socal this was inadvertently left off from prev -- orgnl:  ious e mail \n",
            "\n",
            "-- ip: next draft of letter to i agree with sue is comments and have included her -- prd:  son is comments\n",
            "-- ip: next draft of letter to i agree with sue is comments and have included her -- orgnl:  changes on page \n",
            "\n",
            "-- ip: future article com outsourcing sha -- prd:  ckleton enron north\n",
            "-- ip: future article com outsourcing sha -- orgnl:  red service operations \n",
            "\n",
            "-- ip: pngc comments on the planning see attached file scheduli -- prd:  ng coordinator comments\n",
            "-- ip: pngc comments on the planning see attached file scheduli -- orgnl:  ng coordinator comments \n",
            "\n",
            "-- ip: skew project these calcs are -- prd:  ting for and\n",
            "-- ip: skew project these calcs are -- orgnl:  for puts and for \n",
            "\n",
            "-- ip: manti operating company should you have questio -- prd:  ns please contact\n",
            "-- ip: manti operating company should you have questio -- orgnl:  ns please contact \n",
            "\n",
            "-- ip: rio nogales greg attached for your further handling is the nogal -- prd:  es for paperboard\n",
            "-- ip: rio nogales greg attached for your further handling is the nogal -- orgnl:  es interconnect agreement \n",
            "\n",
            "-- ip: section notes from if you have problems reading this import -- prd:  let me know\n",
            "-- ip: section notes from if you have problems reading this import -- orgnl:  ing it let \n",
            "\n",
            "-- ip: dr.evil just heard some austin powers sound reverbe -- prd:  rate through the\n",
            "-- ip: dr.evil just heard some austin powers sound reverbe -- orgnl:  rate through the \n",
            "\n",
            "-- ip: questions he returns ann -- prd:  ual trading program\n",
            "-- ip: questions he returns ann -- orgnl:  ual leave on \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6959326443655683"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18kpyWl8BhM-"
      },
      "source": [
        "##Beam Search Decoder Predict\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYF-wohIee0o"
      },
      "source": [
        "# Beam Search method understood from https://towardsdatascience.com/an-intuitive-explanation-of-beam-search-9b1d744e7a0f\r\n",
        "import copy\r\n",
        "def beam_predict(input_sentence,model):\r\n",
        "\r\n",
        "  '''\r\n",
        "  Follow the same steps as normal predict function till generating encoder's output.\r\n",
        "  After that we use beam search logic.\r\n",
        "  Generate top three predictions by passing <start> as input.\r\n",
        "  Pass those 3 words as input to decoder and generate top three words for each word.\r\n",
        "  Thus we have total 9 combinatios. We filter out top 3 with high probabilities and \r\n",
        "  pass the last word of that combination to the next step of decoder and repeat the process until we encounter <end> in three sentences\r\n",
        "  '''\r\n",
        "  \r\n",
        "  encoder_test_tokens = tokenizer_encoder.texts_to_sequences([input_sentence])\r\n",
        "  padded_encoder_input = pad_sequences(encoder_test_tokens, maxlen=16, dtype='float32', padding='post')\r\n",
        "  encoder = model.layers[2]\r\n",
        "  encoder_op, enc_h, enc_c = encoder(padded_encoder_input)\r\n",
        "  decoder = model.layers[3]\r\n",
        "  index_of_start = np.array(tokenizer_decoder.word_index['<start>']).reshape(1,1)\r\n",
        "  embedd = decoder.embedding(index_of_start)\r\n",
        "  decoder_op, state_h,state_c = decoder.lstm(embedd,(enc_h,enc_c))\r\n",
        "  states = (state_h,state_c)\r\n",
        "  dense = model.layers[5]\r\n",
        "  op=dense(decoder_op)\r\n",
        "  toppred = np.argsort(op[0][0])[-3:][::-1]\r\n",
        "  probs = np.sort(op[0][0])[-3:][::-1]\r\n",
        "  words = []\r\n",
        "  for pred in toppred:\r\n",
        "    word = [k for k in tokenizer_decoder.word_index if tokenizer_decoder.word_index[k]==pred][0]\r\n",
        "    words.append(word)\r\n",
        "  semi_final = [[probs[0],[toppred[0]],[words[0]],states],[probs[1],[toppred[1]],[words[1]],states],[probs[2],[toppred[2]],[words[2]],states]]\r\n",
        "  finished_sentences = 0\r\n",
        "  final = []\r\n",
        "  while (True):\r\n",
        "    temp = []\r\n",
        "    for i in range(len(semi_final)):\r\n",
        "      dec_emb= decoder.embedding(semi_final[i][1][-1].reshape(1,1))\r\n",
        "      predicted_out,state_h,state_c=decoder.lstm(dec_emb,semi_final[i][-1])\r\n",
        "      op = dense(predicted_out)\r\n",
        "      toppred = np.argsort(op[0][0])[-len(semi_final):][::-1]\r\n",
        "      probs = np.sort(op[0][0])[-len(semi_final):][::-1]\r\n",
        "      states= (state_h, state_c)\r\n",
        "      for j in range(len(toppred)):\r\n",
        "        word = [k for k in tokenizer_decoder.word_index if tokenizer_decoder.word_index[k]==toppred[j]][0]\r\n",
        "        #temp[str(i)+','+str(j)] = (semi_final[i][0] * probs[j],toppred[j],semi_final[i][2].append(word),states)\r\n",
        "        words = copy.deepcopy(semi_final[i][2])\r\n",
        "        words.append(word)\r\n",
        "        temp.append([semi_final[i][0] * probs[j],[toppred[j]],words,states])\r\n",
        "    temp = sorted(temp,key = lambda x:x[0],reverse=True)[:len(semi_final)]\r\n",
        "    ids_to_be_removed = []\r\n",
        "    for id,k in enumerate(temp):\r\n",
        "      if k[2][-1] == '<end>':\r\n",
        "        final.append((k[0],' '.join(k[2][:-1])))\r\n",
        "        finished_sentences+=1\r\n",
        "        ids_to_be_removed.append(id)\r\n",
        "    for id in ids_to_be_removed:\r\n",
        "      temp[id] = 0\r\n",
        "    temp = [i for i in temp if i!=0]\r\n",
        "    semi_final=temp\r\n",
        "    if finished_sentences == 3:\r\n",
        "      break\r\n",
        "\r\n",
        "  return final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptNwl0qte4uX",
        "outputId": "108e6085-9751-4f7f-e55a-d0bf0cc4a17e"
      },
      "source": [
        "sample = new_data.sample(15)\r\n",
        "blue_scores=[]\r\n",
        "for i in sample.index:\r\n",
        "  predicted = beam_predict(new_data.loc[i]['input'],loaded_model)\r\n",
        "  original = [x for x in new_data.loc[i]['decoder_input'].split() if x!='<start>']\r\n",
        "  print('-- ip:',new_data.loc[i]['input'],'-- prd: ' ,[x[1] for x in predicted])\r\n",
        "  print('-- ip:',new_data.loc[i]['input'],'-- orgnl: ' ,' '.join(original),'\\n')\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- ip: revised medusa docs the revisions are all to make it clear that this -- prd:  ['change was discussed', 'change are discussed', 'change is correct']\n",
            "-- ip: revised medusa docs the revisions are all to make it clear that this -- orgnl:  is a nonbinding \n",
            "\n",
            "-- ip: please call me when you get in to -- prd:  ['meet today', 'see you', 'call you']\n",
            "-- ip: please call me when you get in to -- orgnl:  discuss hole \n",
            "\n",
            "-- ip: draft re interactions with pge marlene huntsinger afr -- prd:  ['anji michele farrell', 'anji sager carol', 'anji farrell to']\n",
            "-- ip: draft re interactions with pge marlene huntsinger afr -- orgnl:  anji michele farrell \n",
            "\n",
            "-- ip: ena teams percentage allocations the attached document is being forwarded at the -- prd:  ['request of jeff', 'transwestern pipeline company', 'western customer services']\n",
            "-- ip: ena teams percentage allocations the attached document is being forwarded at the -- orgnl:  request of \n",
            "\n",
            "-- ip: here is the schedule for the pla -- prd:  ['nt and the', 'nning an and', 'nt of march']\n",
            "-- ip: here is the schedule for the pla -- orgnl:  nt and the \n",
            "\n",
            "-- ip: confirmation please find confi -- prd:  ['rmations for and', 'rmation for astra', 'rmation for march']\n",
            "-- ip: confirmation please find confi -- orgnl:  rmation for astra \n",
            "\n",
            "-- ip: change order it is throu -- prd:  ['gh the system', 'gh sunday early', 'gh sunday please']\n",
            "-- ip: change order it is throu -- orgnl:  gh the system \n",
            "\n",
            "-- ip: oasis posting reserve service power gov oasis buspra -- prd:  ['ctices forum messageview', 'west power system', 'west oasis dpr']\n",
            "-- ip: oasis posting reserve service power gov oasis buspra -- orgnl:  ctices forum messageview \n",
            "\n",
            "-- ip: a question regarding your paper in my original calculations i -- prd:  ['did very', 'did not', 'did make']\n",
            "-- ip: a question regarding your paper in my original calculations i -- orgnl:  used n \n",
            "\n",
            "-- ip: southern union gas company and i prep -- prd:  ['are the sign the', 'are the following the', 'are the sign by']\n",
            "-- ip: southern union gas company and i prep -- orgnl:  are the agreement \n",
            "\n",
            "-- ip: txu energy trading company please let me know if -- prd:  ['you have any', 'ted have any', 'ted have questions']\n",
            "-- ip: txu energy trading company please let me know if -- orgnl:  you have \n",
            "\n",
            "-- ip: start date hourahead hour codesite log messages parsing file o westd -- prd:  ['esk california scheduling', 'esk scheduling schedules', 'esk scheduling iso']\n",
            "-- ip: start date hourahead hour codesite log messages parsing file o westd -- orgnl:  esk california scheduling \n",
            "\n",
            "-- ip: qf shutdown message board please post inform -- prd:  ['ation you feel', 'ation contact you', 'ation contact your']\n",
            "-- ip: qf shutdown message board please post inform -- orgnl:  ation you feel \n",
            "\n",
            "-- ip: midamerican meter that need to be pulled and read -- prd:  ['ings added to', 'ings added for', 'rs for june']\n",
            "-- ip: midamerican meter that need to be pulled and read -- orgnl:  ings input for \n",
            "\n",
            "-- ip: japan power plant statement read we will keep -- prd:  ['ing them out', 'ing similar to', 'ing similar procedures']\n",
            "-- ip: japan power plant statement read we will keep -- orgnl:  you apprised of further \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpHKaSh9VAG2"
      },
      "source": [
        "#Attention \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roVAyi5MVEC1"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\r\n",
        "\r\n",
        "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\r\n",
        "\r\n",
        "        '''\r\n",
        "        Initialize the embedding and LSTM layers in encoder\r\n",
        "        '''\r\n",
        "\r\n",
        "        super().__init__()\r\n",
        "        self.lstm_size = lstm_size\r\n",
        "        self.embedding = Embedding(input_dim=inp_vocab_size, output_dim=embedding_size, input_length=input_length,\r\n",
        "                    mask_zero=True, name=\"embedding_layer_encoder\", weights=[embedding_matrix_enc], trainable=True)\r\n",
        "        # self.embedding = Embedding(input_dim=inp_vocab_size, output_dim=embedding_size, input_length=input_length,\r\n",
        "        #                            mask_zero=True, name=\"embedding_layer_encoder\")\r\n",
        "        self.lstm = LSTM(lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\r\n",
        "        self.lstm_output = 0\r\n",
        "        self.lstm_state_h=0\r\n",
        "        self.lstm_state_c=0\r\n",
        "\r\n",
        "    \r\n",
        "    def call(self,input_sequence):\r\n",
        "        \r\n",
        "        '''\r\n",
        "        Takes input sequence as input, pass it to embedding layer, passes its output to lstm layer and returns the lstm output\r\n",
        "        '''\r\n",
        "        \r\n",
        "        input_embedd = self.embedding(input_sequence)\r\n",
        "        self.lstm_output, self.lstm_state_h,self.lstm_state_c = self.lstm(input_embedd)#,initial_state=states)\r\n",
        "        return self.lstm_output, self.lstm_state_h,self.lstm_state_c\r\n",
        "\r\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnrTKwp-VYiv"
      },
      "source": [
        "class Attention(tf.keras.layers.Layer):\r\n",
        "  \r\n",
        "  def __init__(self,scoring_function, enc_units, dec_units,name='attention_layer'):\r\n",
        "    super().__init__(name=name)\r\n",
        "\r\n",
        "    if scoring_function=='dot':\r\n",
        "      self.scoring_function = scoring_function\r\n",
        "      pass\r\n",
        "      \r\n",
        "  def call(self,decoder_hidden_state,encoder_output):\r\n",
        "    \r\n",
        "    '''\r\n",
        "      Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.\r\n",
        "      * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.\r\n",
        "        Multiply the score function with your encoder_outputs to get the context vector.\r\n",
        "        Function returns context vector and attention weights(softmax - scores)\r\n",
        "    '''\r\n",
        "    \r\n",
        "    decoder_hidden_state = tf.expand_dims(decoder_hidden_state, axis=1)\r\n",
        "    if self.scoring_function == 'dot':\r\n",
        "      score = tf.matmul(decoder_hidden_state, encoder_output, transpose_b=True)\r\n",
        "      score = tf.transpose(score,[0,2,1])\r\n",
        "      attention_weights = tf.nn.softmax(score, axis=1)\r\n",
        "      context_vector = tf.reduce_sum(attention_weights*encoder_output,axis=1)\r\n",
        "      return context_vector, attention_weights\r\n",
        "      pass\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d50VOscTVo6G"
      },
      "source": [
        "class One_Step_Decoder(tf.keras.layers.Layer):\r\n",
        "  def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,enc_units,name='onestep_decoder'):\r\n",
        "      \r\n",
        "      '''Initialize decoder embedding layer, LSTM and any other objects needed'''\r\n",
        "      \r\n",
        "      super().__init__(name=name)\r\n",
        "      self.embedding = Embedding(input_dim=tar_vocab_size, output_dim=embedding_dim, input_length=input_length,\r\n",
        "                          mask_zero=True, name=\"embedding_layer_decoder\", weights=[embedding_matrix_dec], trainable=True)\r\n",
        "      self.lstm = LSTM(dec_units, return_state=True, name=\"Decoder_LSTM\")\r\n",
        "      self.dense = Dense(tar_vocab_size,name='Decoder_dense')\r\n",
        "      self.attention=Attention(score_fun,enc_units,dec_units)\r\n",
        "      self.embedding_dim = embedding_dim\r\n",
        "      self.enc_units = enc_units\r\n",
        "      self.dec_units = dec_units\r\n",
        "      self.score_fun = score_fun\r\n",
        "\r\n",
        "  @tf.function(input_signature=(tf.TensorSpec(shape=[None, 1], dtype=tf.float32),tf.TensorSpec(shape=[None, 16,512], dtype=tf.float32),\r\n",
        "                                tf.TensorSpec(shape=[None, 512], dtype=tf.float32),tf.TensorSpec(shape=[None, 512], dtype=tf.float32)))\r\n",
        "  def call(self,input_to_decoder, encoder_output, state_h,state_c):\r\n",
        "    \r\n",
        "    '''\r\n",
        "    Take input to decoder at a particular step. Pass it to embedding layer, \r\n",
        "    Pass the previous steps hidden state and encoder output (of all steps) as input to attention layer to calculate the context vector\r\n",
        "    concat that context vector with the embedded input and pass that concated matrix as input to lstm \r\n",
        "    pass lstm output to dense layer and return the result\r\n",
        "    '''\r\n",
        "\r\n",
        "    input_embedd = self.embedding(input_to_decoder)\r\n",
        "    context_vector,attention_weights=self.attention(state_h,encoder_output)\r\n",
        "    concat = tf.concat([input_embedd,tf.reshape(context_vector,[-1,1,self.enc_units])], axis=-1)\r\n",
        "    lstm_output, state_h,state_c = self.lstm(concat,initial_state=(state_h,state_c))\r\n",
        "    result = self.dense(lstm_output)\r\n",
        "    return result, state_h,state_c, attention_weights,context_vector\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpushSAOV9wV"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer): \r\n",
        "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,enc_units,name='decoder_layer'):\r\n",
        "      \r\n",
        "      '''Intialize necessary variables and create an object from the class onestepdecoder'''\r\n",
        "      \r\n",
        "      super().__init__(name=name)\r\n",
        "      self.onestepdecoder = onestepdecoder=One_Step_Decoder(out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,enc_units) \r\n",
        "     \r\n",
        "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state):\r\n",
        "        \r\n",
        "        '''Pass input to decoder and encoder output and decoder hidden states as input,\r\n",
        "        Use all of them by passing decoder input one by one to generate the words at each step.\r\n",
        "        Store them in a tensorarray and return them'''\r\n",
        "\r\n",
        "        all_outputs = tf.TensorArray(tf.float32, size=tf.shape(input_to_decoder)[1], name='output_arrays')\r\n",
        "        for timestep in range(5): \r\n",
        "            output,decoder_hidden_state,decoder_cell_state,attention_weights,context_vector = self.onestepdecoder(input_to_decoder[:,timestep:timestep+1],encoder_output,decoder_hidden_state,decoder_cell_state)\r\n",
        "            all_outputs = all_outputs.write(timestep,output)\r\n",
        "        all_outputs = tf.transpose(all_outputs.stack(),[1,0,2])\r\n",
        "\r\n",
        "        return all_outputs\r\n",
        "        \r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o50yJuUdgnYh"
      },
      "source": [
        "def custom_lossfunction(targets,logits):\r\n",
        "\r\n",
        "  # Custom loss function that will not consider the loss for padded zeros.\r\n",
        "  # Refer https://www.tensorflow.org/tutorials/text/nmt_with_attention#define_the_optimizer_and_the_loss_function\r\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\r\n",
        "  mask = tf.math.logical_not(tf.math.equal(targets, 0))\r\n",
        "  loss_ = loss_object(targets, logits)\r\n",
        "\r\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\r\n",
        "  loss_ *= mask\r\n",
        "\r\n",
        "  return tf.reduce_mean(loss_)\r\n",
        "\r\n",
        "tf.keras.losses.custom_loss = custom_lossfunction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSepNWDmWOlJ",
        "outputId": "3d32fee1-5c0c-486b-fb54-64214f4904de"
      },
      "source": [
        "'''Create a functional model using the custom layers built above'''\r\n",
        "\r\n",
        "embed_dim = 300\r\n",
        "enc_input_length = max_len_enc\r\n",
        "dec_input_length = max_len_dec\r\n",
        "lstm_units = 512\r\n",
        "\r\n",
        "X_input1 = Input(shape=(max_len_enc,))\r\n",
        "X_input2 = Input(shape=(max_len_dec,))\r\n",
        "X_input3 = Input(shape=(max_len_dec,))\r\n",
        "\r\n",
        "encoder_output, encoder_h, encoder_c = Encoder(inp_vocab_size=vocab_size_enc, embedding_size=embed_dim,\r\n",
        "                                               input_length=enc_input_length, lstm_size = lstm_units)(X_input1)\r\n",
        "decoder_output= Decoder(out_vocab_size=vocab_size_dec, embedding_dim=embed_dim,input_length=dec_input_length,\r\n",
        "                        dec_units= lstm_units ,score_fun='dot' ,enc_units= lstm_units)(X_input2,encoder_output,encoder_h,encoder_c)\r\n",
        "\r\n",
        "model = Model(inputs = [[X_input1,X_input2],X_input3], outputs = decoder_output)\r\n",
        "optimizer = tf.keras.optimizers.Adam()\r\n",
        "model.compile(optimizer=optimizer,loss=custom_lossfunction) \r\n",
        "train_steps=new_data.shape[0]//BATCH_SIZE\r\n",
        "\r\n",
        "history = model.fit(train_dataset, steps_per_epoch=train_steps, epochs=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "762/762 [==============================] - 384s 499ms/step - loss: 4.5603\n",
            "Epoch 2/30\n",
            "762/762 [==============================] - 392s 515ms/step - loss: 3.5188\n",
            "Epoch 3/30\n",
            "762/762 [==============================] - 394s 517ms/step - loss: 2.9885\n",
            "Epoch 4/30\n",
            "762/762 [==============================] - 393s 516ms/step - loss: 2.6516\n",
            "Epoch 5/30\n",
            "762/762 [==============================] - 394s 517ms/step - loss: 2.3829\n",
            "Epoch 6/30\n",
            "762/762 [==============================] - 393s 516ms/step - loss: 2.1561\n",
            "Epoch 7/30\n",
            "762/762 [==============================] - 394s 516ms/step - loss: 1.9598\n",
            "Epoch 8/30\n",
            "762/762 [==============================] - 392s 515ms/step - loss: 1.7932\n",
            "Epoch 9/30\n",
            "762/762 [==============================] - 394s 517ms/step - loss: 1.6455\n",
            "Epoch 10/30\n",
            "762/762 [==============================] - 394s 517ms/step - loss: 1.5140\n",
            "Epoch 11/30\n",
            "762/762 [==============================] - 392s 514ms/step - loss: 1.3934\n",
            "Epoch 12/30\n",
            "762/762 [==============================] - 393s 516ms/step - loss: 1.2848\n",
            "Epoch 13/30\n",
            "762/762 [==============================] - 393s 516ms/step - loss: 1.1857\n",
            "Epoch 14/30\n",
            "762/762 [==============================] - 393s 515ms/step - loss: 1.0975\n",
            "Epoch 15/30\n",
            "762/762 [==============================] - 394s 517ms/step - loss: 1.0147\n",
            "Epoch 16/30\n",
            "762/762 [==============================] - 393s 516ms/step - loss: 0.9425\n",
            "Epoch 17/30\n",
            "762/762 [==============================] - 393s 516ms/step - loss: 0.8730\n",
            "Epoch 18/30\n",
            "762/762 [==============================] - 394s 517ms/step - loss: 0.8107\n",
            "Epoch 19/30\n",
            "762/762 [==============================] - 395s 518ms/step - loss: 0.7530\n",
            "Epoch 20/30\n",
            "762/762 [==============================] - 393s 516ms/step - loss: 0.7022\n",
            "Epoch 21/30\n",
            "762/762 [==============================] - 394s 517ms/step - loss: 0.6505\n",
            "Epoch 22/30\n",
            "762/762 [==============================] - 393s 516ms/step - loss: 0.6026\n",
            "Epoch 23/30\n",
            "762/762 [==============================] - 393s 516ms/step - loss: 0.5610\n",
            "Epoch 24/30\n",
            "762/762 [==============================] - 393s 515ms/step - loss: 0.5247\n",
            "Epoch 25/30\n",
            "762/762 [==============================] - 394s 517ms/step - loss: 0.4909\n",
            "Epoch 26/30\n",
            "762/762 [==============================] - 393s 516ms/step - loss: 0.4554\n",
            "Epoch 27/30\n",
            "762/762 [==============================] - 393s 516ms/step - loss: 0.4257\n",
            "Epoch 28/30\n",
            "762/762 [==============================] - 395s 518ms/step - loss: 0.4019\n",
            "Epoch 29/30\n",
            "762/762 [==============================] - 394s 517ms/step - loss: 0.3768\n",
            "Epoch 30/30\n",
            "762/762 [==============================] - 394s 517ms/step - loss: 0.3506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEQ5MnD-ypFL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "262cba77-70b7-4b2c-c68f-bb74b7e1a433"
      },
      "source": [
        "history = model.fit(train_dataset, steps_per_epoch=train_steps, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "762/762 [==============================] - 388s 509ms/step - loss: 0.2306\n",
            "Epoch 2/5\n",
            "762/762 [==============================] - 398s 522ms/step - loss: 0.2180\n",
            "Epoch 3/5\n",
            "762/762 [==============================] - 397s 521ms/step - loss: 0.2082\n",
            "Epoch 4/5\n",
            "762/762 [==============================] - 397s 522ms/step - loss: 0.1979\n",
            "Epoch 5/5\n",
            "762/762 [==============================] - 398s 522ms/step - loss: 0.1917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "k6G8ov5jOgFu",
        "outputId": "9089fdfc-e2ee-4281-f559-9cb8733baf36"
      },
      "source": [
        "# Plot training & validation iou_score values\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "plt.figure(figsize=(10, 5))\r\n",
        "plt.plot(history.history['loss'])\r\n",
        "plt.title('Model loss')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.legend(['Train'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGYeJy8eeAyd",
        "outputId": "43a6f9ca-9eab-4202-ef7d-0b395b657992"
      },
      "source": [
        "model.save('final_attention_subject_upd')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_encoder_layer_call_fn, embedding_layer_encoder_layer_call_and_return_conditional_losses, embedding_layer_encoder_layer_call_fn, embedding_layer_encoder_layer_call_and_return_conditional_losses, embedding_layer_encoder_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as embedding_layer_encoder_layer_call_fn, embedding_layer_encoder_layer_call_and_return_conditional_losses, embedding_layer_encoder_layer_call_fn, embedding_layer_encoder_layer_call_and_return_conditional_losses, embedding_layer_encoder_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: final_attention_subject_upd/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: final_attention_subject_upd/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qz1wcS_thTHu"
      },
      "source": [
        "loaded_model_att = tf.keras.models.load_model('final_attention_subject_upd',custom_objects={'custom_lossfunction':custom_lossfunction})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc5eygLWrclh",
        "outputId": "5b880e1a-760a-4dfc-9dd6-f1d20cc64ebd"
      },
      "source": [
        "loaded_model_att.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 16)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, 5)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_1 (Encoder)             ((None, 16, 512), (N 15132924    input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 5)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_layer (Decoder)         (None, None, 34335)  30627955    input_5[0][0]                    \n",
            "                                                                 encoder_1[0][2]                  \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 45,760,879\n",
            "Trainable params: 45,760,879\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOLkahUYhZ0I"
      },
      "source": [
        "def predict(input_sentence,model):\r\n",
        "  \r\n",
        "  '''\r\n",
        "  Given an input sentence, we need to predict the next words.\r\n",
        "  Tokenize and pad the input sentence,\r\n",
        "  Pass it to encoder's embedding layer and its output to encoder's LSTM layer.\r\n",
        "  Pass its final states hidden and cell states as inputs to decoder's LSTM\r\n",
        "  Pass the encoder's output of all time steps as input to one step decoder to calculate context vector using attention weights\r\n",
        "  Append that context vector with decoder's current step to predict the next time steps output.\r\n",
        "  Before that, initialize <start> word and pass it to decoders embedding layer and then to LSTM layer,\r\n",
        "  We run a loop till we get <end> word.\r\n",
        "  We give predicted word at decoder's current step as input to its next step.\r\n",
        "  '''\r\n",
        "\r\n",
        "  encoder_test_tokens = tokenizer_encoder.texts_to_sequences([input_sentence])\r\n",
        "  padded_encoder_input = pad_sequences(encoder_test_tokens, maxlen=16, dtype='float32', padding='post')\r\n",
        "  encoder = model.layers[2]\r\n",
        "  encoder_op, enc_h, enc_c = encoder(padded_encoder_input)\r\n",
        "  decoder = model.layers[4]\r\n",
        "  index_of_start = np.array(tokenizer_decoder.word_index['<start>']).reshape(1,1).astype('float32')\r\n",
        "  pred=0\r\n",
        "  sentence = []\r\n",
        "  attention_weights=[]\r\n",
        "  # att_wgts = tf.TensorArray(dtype=tf.float32, dynamic_size=True,size=0)\r\n",
        "  while pred!=tokenizer_decoder.word_index['<end>']:\r\n",
        "    predicted_out,enc_h, enc_c,attention,context_vector = decoder.onestepdecoder(index_of_start,encoder_op, enc_h, enc_c)\r\n",
        "    pred = np.argmax(predicted_out) \r\n",
        "    word = [k for k in tokenizer_decoder.word_index if tokenizer_decoder.word_index[k]==(pred)][0]\r\n",
        "    sentence.append(word)\r\n",
        "    index_of_start = np.array(pred).reshape(1,1).astype('float32')\r\n",
        "\r\n",
        "  return ' '.join(sentence[:-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfsZcYgfQHSk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8051980-3187-4c96-f7d0-148c185bad77"
      },
      "source": [
        "import numpy as np\r\n",
        "sample = new_data.sample(100000,random_state=42)\r\n",
        "import nltk.translate.bleu_score as bleu\r\n",
        "from tqdm import tqdm\r\n",
        "incorrect_predictions_att=[]\r\n",
        "for i in tqdm(sample.index):\r\n",
        "  predicted = predict(new_data.loc[i]['input'],loaded_model_att)\r\n",
        "  predicted_sent = predicted.split()\r\n",
        "  original = [x for x in new_data.loc[i]['decoder_input'].split() if x!='<start>']\r\n",
        "  if bleu.sentence_bleu([original],predicted_sent)<0.2:\r\n",
        "    incorrect_predictions_att.append((new_data.loc[i]['input'],' '.join(original),predicted))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [1:23:01<00:00, 20.07it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZOFJNx5XglE",
        "outputId": "f4ca0a29-cd88-4105-8bac-2b620dec5b2e"
      },
      "source": [
        "for i in range(20,40):\r\n",
        "  print(incorrect_predictions_att[i][0],\"_\",incorrect_predictions_att[i][1],'_',incorrect_predictions_att[i][2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hard lessons from california if you have any _ questions do not _ thing off the\n",
            "congrats i met bro _ wn at a _ ker last week\n",
            "charts i am for _ wading some charts _ ward on the\n",
            "cuts by the ciso please refer to transalta _ tag numbers w _ an thomas northern\n",
            "counterparties western gas resources anyone _ please let me _ ng it is\n",
            "behavior update i did not assign _ her a consequence _ ed to anything\n",
            "delano for sunday monday when you contact the control room please _ only speak in _ ed our settlements\n",
            "baby shower just kidding hope you _ all are doing _ can not find\n",
            "nobody scheduled on day shift please let me know _ what you would _ when these are\n",
            "sorry sean just changed this _ deal from _ ed to sell\n",
            "omnibus revisions we may come _ up with more omnibus _ back out as to\n",
            "l visa documents my address is as follows barry _ tycholiz c o enron _ ton mark e\n",
            "island ecn inc. confidentiality agreement please find attached a copy _ of the _ for his\n",
            "undeliverable var rate sheet o enron ou _ na cn recipients cn _ ks llc work\n",
            "i ll be late there is now a _ meeting at pm _ est market in\n",
            "penalty charges the trader over there is _ jb smith _ an average\n",
            "geodes desertusa please print out this page _ about geodes _ and use\n",
            "thanks. ben thanks for having _ us up to _ one on my\n",
            "here it is... mark did rece _ ive your email _ ived tiger natural\n",
            "doyle equity earnings loss i am now told that he will not _ sell doyle _ hing the books\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhY3Q-YDF7oi"
      },
      "source": [
        "import pickle\r\n",
        "outfile = open('incorrect_preds_att.pkl','wb')\r\n",
        "pickle.dump(incorrect_predictions_att,outfile)\r\n",
        "outfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7i5LtR9XQT_r",
        "outputId": "afb853b2-fc88-487f-edd5-8d8c4d2f5553"
      },
      "source": [
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "sample = new_data.sample(1000)\r\n",
        "import nltk.translate.bleu_score as bleu\r\n",
        "\r\n",
        "blue_scores=[]\r\n",
        "for n,i in enumerate(sample.index):\r\n",
        "  input_sentence = sample.loc[i]['input']\r\n",
        "  predicted = predict(input_sentence,loaded_model_att)\r\n",
        "  predicted = predicted.split()\r\n",
        "  original = [x for x in sample.loc[i]['decoder_input'].split() if x!='<start>']\r\n",
        "  if n in range(50):\r\n",
        "    print('-- ip:',new_data.loc[i]['input'],'-- prd: ' ,' '.join(predicted))\r\n",
        "    print('-- ip:',new_data.loc[i]['input'],'-- orgnl: ' ,' '.join(original),'\\n')\r\n",
        "\r\n",
        "  blue_scores.append(bleu.sentence_bleu([original],predicted))\r\n",
        "\r\n",
        "np.mean(blue_scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- ip: materials for scott mcnealy does that work for you best dasovi -- prd:  ch enron corp\n",
            "-- ip: materials for scott mcnealy does that work for you best dasovi -- orgnl:  ch enron corp \n",
            "\n",
            "-- ip: action required time entry due if you have log prob -- prd:  lems call the\n",
            "-- ip: action required time entry due if you have log prob -- orgnl:  lems call the \n",
            "\n",
            "-- ip: loss of a leader i want to see this -- prd:  but we\n",
            "-- ip: loss of a leader i want to see this -- orgnl:  house you \n",
            "\n",
            "-- ip: erv please shout with questio -- prd:  ns or concerns\n",
            "-- ip: erv please shout with questio -- orgnl:  ns or concerns \n",
            "\n",
            "-- ip: salmon energy records delta power do one of you gentlemen have this we are getting -- prd:  them for signature\n",
            "-- ip: salmon energy records delta power do one of you gentlemen have this we are getting -- orgnl:  close to closing \n",
            "\n",
            "-- ip: fw comments on footnotes sent from my wirele -- prd:  ss handheld www\n",
            "-- ip: fw comments on footnotes sent from my wirele -- orgnl:  ss handheld www \n",
            "\n",
            "-- ip: inland paperboard changes in whata -- prd:  yathink i will\n",
            "-- ip: inland paperboard changes in whata -- orgnl:  yathink i will \n",
            "\n",
            "-- ip: lower colorado river authority the document will scan -- prd:  ned into the\n",
            "-- ip: lower colorado river authority the document will scan -- orgnl:  ned into livelink \n",
            "\n",
            "-- ip: test are you there sent from my wirel -- prd:  ess handheld www\n",
            "-- ip: test are you there sent from my wirel -- orgnl:  ess handheld www \n",
            "\n",
            "-- ip: bear guarantee letter i had asked him about when they will execut -- prd:  ing these documents\n",
            "-- ip: bear guarantee letter i had asked him about when they will execut -- orgnl:  ing the agreement \n",
            "\n",
            "-- ip: phelps dodge the same percentage decrease in dem -- prd:  and is what\n",
            "-- ip: phelps dodge the same percentage decrease in dem -- orgnl:  and is what \n",
            "\n",
            "-- ip: enserco l.l.c. richard lauer is requesting that acco -- prd:  unt be opened\n",
            "-- ip: enserco l.l.c. richard lauer is requesting that acco -- orgnl:  unt be opened \n",
            "\n",
            "-- ip: promotion i definately would like nomina -- prd:  te into the\n",
            "-- ip: promotion i definately would like nomina -- orgnl:  te bob superty \n",
            "\n",
            "-- ip: fw real time trader ryan don juan advi -- prd:  se me of\n",
            "-- ip: fw real time trader ryan don juan advi -- orgnl:  se me of \n",
            "\n",
            "-- ip: wti brent trades smith street eb -- prd:  a houston texas phone\n",
            "-- ip: wti brent trades smith street eb -- orgnl:  a houston texas phone \n",
            "\n",
            "-- ip: am i free..... i will miss -- prd:  ing you in\n",
            "-- ip: am i free..... i will miss -- orgnl:  you but go for \n",
            "\n",
            "-- ip: erv notification violation notification memo we are having difficu -- prd:  lty opening notification\n",
            "-- ip: erv notification violation notification memo we are having difficu -- orgnl:  lties with the \n",
            "\n",
            "-- ip: enrononline market descriptions when can expe -- prd:  ct the normal\n",
            "-- ip: enrononline market descriptions when can expe -- orgnl:  ct the remaining \n",
            "\n",
            "-- ip: bid week prices please let me -- prd:  know if you have\n",
            "-- ip: bid week prices please let me -- orgnl:  know if you have \n",
            "\n",
            "-- ip: comercializadora metrogas s.a. de c.v. attached for your approval is -- prd:  a copy of\n",
            "-- ip: comercializadora metrogas s.a. de c.v. attached for your approval is -- orgnl:  the form \n",
            "\n",
            "-- ip: gisb as previously discussed please see attac -- prd:  hed draft of\n",
            "-- ip: gisb as previously discussed please see attac -- orgnl:  hed gisb draft \n",
            "\n",
            "-- ip: caledonia brownsville schedules thanks for everyone is -- prd:  looking for me\n",
            "-- ip: caledonia brownsville schedules thanks for everyone is -- orgnl:  help with the \n",
            "\n",
            "-- ip: court koenning victoria do yah -- prd:  oo send new\n",
            "-- ip: court koenning victoria do yah -- orgnl:  oo send online \n",
            "\n",
            "-- ip: aspect contracts sorry for the delay on this jill i -- prd:  am taking vacation this\n",
            "-- ip: aspect contracts sorry for the delay on this jill i -- orgnl:  was out \n",
            "\n",
            "-- ip: are we going to discuss these with lavo before he -- prd:  firmed the loves\n",
            "-- ip: are we going to discuss these with lavo before he -- orgnl:  makes a decision \n",
            "\n",
            "-- ip: gas counterparties please check metromed -- prd:  ia energy inc\n",
            "-- ip: gas counterparties please check metromed -- orgnl:  ia energy inc \n",
            "\n",
            "-- ip: new ews spend approval guidelines if you have questi -- prd:  ons regarding these\n",
            "-- ip: new ews spend approval guidelines if you have questi -- orgnl:  ons regarding these \n",
            "\n",
            "-- ip: transco demand charge transco has agreed to -- prd:  act with the\n",
            "-- ip: transco demand charge transco has agreed to -- orgnl:  bill pse g \n",
            "\n",
            "-- ip: friday morning funny they swoop down hung -- prd:  rily begin eating\n",
            "-- ip: friday morning funny they swoop down hung -- orgnl:  rily begin eating \n",
            "\n",
            "-- ip: nov pnr billing tw attached is deta -- prd:  il for our\n",
            "-- ip: nov pnr billing tw attached is deta -- orgnl:  il for park \n",
            "\n",
            "-- ip: ivey alumni calgary event nov laurel i have transfe -- prd:  rred to houston\n",
            "-- ip: ivey alumni calgary event nov laurel i have transfe -- orgnl:  rred to houston \n",
            "\n",
            "-- ip: esource presents free lexis nexis if you do not have one a -- prd:  se contact fax\n",
            "-- ip: esource presents free lexis nexis if you do not have one a -- orgnl:  guest id will \n",
            "\n",
            "-- ip: bike commute challenge tully trade floor port -- prd:  land desk cell\n",
            "-- ip: bike commute challenge tully trade floor port -- orgnl:  land desk cell \n",
            "\n",
            "-- ip: curve verification ercot do you have this information i tal -- prd:  ked to peggy\n",
            "-- ip: curve verification ercot do you have this information i tal -- orgnl:  ked to peggy \n",
            "\n",
            "-- ip: dynegy ice vol apr matt motsinger emb -- prd:  edded picture metafile\n",
            "-- ip: dynegy ice vol apr matt motsinger emb -- orgnl:  edded picture metafile \n",
            "\n",
            "-- ip: transport and logistics customer happy the new date thur -- prd:  sday is attached\n",
            "-- ip: transport and logistics customer happy the new date thur -- orgnl:  sday october th \n",
            "\n",
            "-- ip: aram sogomonian phone w w -- prd:  h w h\n",
            "-- ip: aram sogomonian phone w w -- orgnl:  c h \n",
            "\n",
            "-- ip: phillip here is your holiday this is an mail -- prd:  ing sent from\n",
            "-- ip: phillip here is your holiday this is an mail -- orgnl:  ing this message \n",
            "\n",
            "-- ip: tx rec sample confirm ercot awards recs -- prd:  on quarterly caps\n",
            "-- ip: tx rec sample confirm ercot awards recs -- orgnl:  on a quarterly basis \n",
            "\n",
            "-- ip: conference call a draft will circul -- prd:  ated before the\n",
            "-- ip: conference call a draft will circul -- orgnl:  ated before the \n",
            "\n",
            "-- ip: peaker turbine nominal output we will have to use corrected numbers unless info -- prd:  rmation becomes available\n",
            "-- ip: peaker turbine nominal output we will have to use corrected numbers unless info -- orgnl:  rmation becomes available \n",
            "\n",
            "-- ip: enron na agreement comments i hope we fini -- prd:  sh up your\n",
            "-- ip: enron na agreement comments i hope we fini -- orgnl:  sh up next \n",
            "\n",
            "-- ip: a few comments i think mak -- prd:  es sense sense\n",
            "-- ip: a few comments i think mak -- orgnl:  es sense to \n",
            "\n",
            "-- ip: meeting with teb rob and pst alice weekley enron -- prd:  end and development\n",
            "-- ip: meeting with teb rob and pst alice weekley enron -- orgnl:  development wants you \n",
            "\n",
            "-- ip: ets intercompany billing invoices by attached are bil -- prd:  led by p\n",
            "-- ip: ets intercompany billing invoices by attached are bil -- orgnl:  ling invoices by \n",
            "\n",
            "-- ip: citizens let me know if you -- prd:  have any\n",
            "-- ip: citizens let me know if you -- orgnl:  need anything \n",
            "\n",
            "-- ip: tw supply this list does not include the availab -- prd:  le that was\n",
            "-- ip: tw supply this list does not include the availab -- orgnl:  le from interconnects \n",
            "\n",
            "-- ip: term sheet for agreement i have not -- prd:  received it yet but\n",
            "-- ip: term sheet for agreement i have not -- orgnl:  yet heard from goldberg \n",
            "\n",
            "-- ip: updated reserving capacity for current requests for future dated realig -- prd:  nments on firm\n",
            "-- ip: updated reserving capacity for current requests for future dated realig -- orgnl:  nments on firm \n",
            "\n",
            "-- ip: the ferc staff report on bulk power markets is available at the web -- prd:  site http www\n",
            "-- ip: the ferc staff report on bulk power markets is available at the web -- orgnl:  site http www \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7284194247955131"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeVP8WdhQ5_S"
      },
      "source": [
        "import copy\r\n",
        "def beam_predict(input_sentence,model):\r\n",
        "\r\n",
        "  '''\r\n",
        "  Follow the same steps as normal predict function till generating encoder's output.\r\n",
        "  After that we use beam search logic.\r\n",
        "  Generate top three predictions by passing <start> as input.\r\n",
        "  Pass those 3 words as input to one step decoder along with encoder output and generate top three words for each word.\r\n",
        "  Thus we have total 9 combinatios. We filter out top 3 with high probabilities and \r\n",
        "  pass the last word of that combination to the next step of one step decoder and repeat the process until we encounter <end> in three sentences\r\n",
        "  '''\r\n",
        "  \r\n",
        "  encoder_test_tokens = tokenizer_encoder.texts_to_sequences([input_sentence])\r\n",
        "  padded_encoder_input = pad_sequences(encoder_test_tokens, maxlen=16, dtype='float32', padding='post')\r\n",
        "  encoder = model.layers[2]\r\n",
        "  encoder_op, enc_h, enc_c = encoder(padded_encoder_input)\r\n",
        "  decoder = model.layers[4]\r\n",
        "  index_of_start = np.array(tokenizer_decoder.word_index['<start>']).reshape(1,1).astype('float32')\r\n",
        "  predicted_out,enc_h, enc_c,attention,context_vector = decoder.onestepdecoder(index_of_start,encoder_op, enc_h, enc_c)\r\n",
        "  state_h, state_c = enc_h,enc_c\r\n",
        "  states = (state_h, state_c)\r\n",
        "  toppred = np.argsort(predicted_out[0])[-3:][::-1]\r\n",
        "  probs = np.sort(predicted_out[0])[-3:][::-1]\r\n",
        "  words = []\r\n",
        "  for pred in toppred:\r\n",
        "    word = [k for k in tokenizer_decoder.word_index if tokenizer_decoder.word_index[k]==pred][0]\r\n",
        "    words.append(word)\r\n",
        "  semi_final = [[probs[0],[toppred[0]],[words[0]],states],[probs[1],[toppred[1]],[words[1]],states],[probs[2],[toppred[2]],[words[2]],states]]\r\n",
        "  finished_sentences = 0\r\n",
        "  final = []\r\n",
        "  while (True):\r\n",
        "    temp = []\r\n",
        "    for i in range(len(semi_final)):\r\n",
        "      # dec_emb= decoder.embedding(semi_final[i][1][-1].reshape(1,1))\r\n",
        "      predicted_out,state_h, state_c,attention,context_vector = decoder.onestepdecoder(semi_final[i][1][-1].reshape(1,1).astype('float32'),\r\n",
        "                                                                                       encoder_op, semi_final[i][-1][0], semi_final[i][-1][1])\r\n",
        "      toppred = np.argsort(predicted_out[0])[-len(semi_final):][::-1]\r\n",
        "      probs = np.sort(predicted_out[0])[-len(semi_final):][::-1]\r\n",
        "      states= (state_h, state_c)\r\n",
        "      for j in range(len(toppred)):\r\n",
        "        word = [k for k in tokenizer_decoder.word_index if tokenizer_decoder.word_index[k]==toppred[j]][0]\r\n",
        "        #temp[str(i)+','+str(j)] = (semi_final[i][0] * probs[j],toppred[j],semi_final[i][2].append(word),states)\r\n",
        "        words = copy.deepcopy(semi_final[i][2])\r\n",
        "        words.append(word)\r\n",
        "        temp.append([semi_final[i][0] * probs[j],[toppred[j]],words,states])\r\n",
        "    temp = sorted(temp,key = lambda x:x[0],reverse=True)[:len(semi_final)]\r\n",
        "    ids_to_be_removed = []\r\n",
        "    for id,k in enumerate(temp):\r\n",
        "      if k[2][-1] == '<end>':\r\n",
        "        final.append((k[0],' '.join(k[2][:-1])))\r\n",
        "        finished_sentences+=1\r\n",
        "        ids_to_be_removed.append(id)\r\n",
        "    for id in ids_to_be_removed:\r\n",
        "      temp[id] = 0\r\n",
        "    temp = [i for i in temp if i!=0]\r\n",
        "    semi_final=temp\r\n",
        "    if finished_sentences == 3:\r\n",
        "      break\r\n",
        "\r\n",
        "  return final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyJ8AfzklPwW",
        "outputId": "8462a765-89c5-4435-9c5c-85f78f133b05"
      },
      "source": [
        "sample = new_data.sample(15)\r\n",
        "blue_scores=[]\r\n",
        "for i in sample.index:\r\n",
        "  predicted = beam_predict(new_data.loc[i]['input'],loaded_model_att)\r\n",
        "  original = [x for x in new_data.loc[i]['decoder_input'].split() if x!='<start>']\r\n",
        "  print('-- ip:',new_data.loc[i]['input'],'-- prd: ' ,[x[1] for x in predicted])\r\n",
        "  print('-- ip:',new_data.loc[i]['input'],'-- orgnl: ' ,' '.join(original),'\\n')\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- ip: executive reports viewer i received an email morni -- prd:  ['ng regarding the', 'ng and represent', 'ng regarding this']\n",
            "-- ip: executive reports viewer i received an email morni -- orgnl:  ng regarding the \n",
            "\n",
            "-- ip: com ed lois i will bring them up for -- prd:  ['initialling once i', 'initialling once we', 'initialling once that']\n",
            "-- ip: com ed lois i will bring them up for -- orgnl:  initialling once i recieve \n",
            "\n",
            "-- ip: conference call gas curtailment and do we have a -- prd:  ['look at it', 'look into it', 'look at the']\n",
            "-- ip: conference call gas curtailment and do we have a -- orgnl:  call in number \n",
            "\n",
            "-- ip: hr issues jae black east trad -- prd:  ['ing assistant to', 'ing support assistant', 'ing assistant to kevin']\n",
            "-- ip: hr issues jae black east trad -- orgnl:  ing assistant to \n",
            "\n",
            "-- ip: stanford mckinsey case study globe talking with skilling cindy vin -- prd:  ['ce kaminski p', 'ce kaminski vince', 'ce kaminski http']\n",
            "-- ip: stanford mckinsey case study globe talking with skilling cindy vin -- orgnl:  ce kaminski mike \n",
            "\n",
            "-- ip: eol credit approvals as requested please -- prd:  ['ed approval forms', 'approve for enrononline oba', 'ed approval forms for']\n",
            "-- ip: eol credit approvals as requested please -- orgnl:  find attached revised approval \n",
            "\n",
            "-- ip: i am not reading -- prd:  ['putting right now', 'putting right out', 'putting right after']\n",
            "-- ip: i am not reading -- orgnl:  that in public \n",
            "\n",
            "-- ip: she has not answered anything other than -- prd:  ['ks becky x', 'ks for asking', 'ks for your']\n",
            "-- ip: she has not answered anything other than -- orgnl:  the program requirements \n",
            "\n",
            "-- ip: updated spares inventory list please overnite origin -- prd:  ['al to me', 'als to me', 'ator to me']\n",
            "-- ip: updated spares inventory list please overnite origin -- orgnl:  al to me \n",
            "\n",
            "-- ip: hpl transition contact list attached is cont -- prd:  ['act list for', 'act information for', 'act list of']\n",
            "-- ip: hpl transition contact list attached is cont -- orgnl:  act list for \n",
            "\n",
            "-- ip: internet sports network inc. a copy will be sent to dave samuels -- prd:  ['for your help', 'for this article', 'for the enron']\n",
            "-- ip: internet sports network inc. a copy will be sent to dave samuels -- orgnl:  for the \n",
            "\n",
            "-- ip: cg e agreements my contacts at cg e have been paul -- prd:  ['jett and', 'jett at', 'jett jett and']\n",
            "-- ip: cg e agreements my contacts at cg e have been paul -- orgnl:  jett and \n",
            "\n",
            "-- ip: vaccine please reserve one flu -- prd:  ['vaccine in for', 'vaccine for at', 'vaccine for mike']\n",
            "-- ip: vaccine please reserve one flu -- orgnl:  vaccine for mike \n",
            "\n",
            "-- ip: ena delta documents revised carolyn please send to counter -- prd:  ['party subject to', 'party original to', 'party regarding the']\n",
            "-- ip: ena delta documents revised carolyn please send to counter -- orgnl:  party subject to \n",
            "\n",
            "-- ip: wednesday meeting any other use of -- prd:  ['your email address', 'the email by', 'the email or']\n",
            "-- ip: wednesday meeting any other use of -- orgnl:  the email by \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RKnc6DMnMDq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikjnslHeN8XR"
      },
      "source": [
        "#Analysis of incorrect predictions from both models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VzsTHFWOAat"
      },
      "source": [
        "import pickle\r\n",
        "infile = open('incorrect_preds.pkl','rb')\r\n",
        "incorrect_predictions = pickle.load(infile)\r\n",
        "infile.close()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbqwWyztO7Wl"
      },
      "source": [
        "import random\r\n",
        "sampless = random.sample(range(len(incorrect_predictions)), 25)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uiey7sxXOCkG",
        "outputId": "28b35bc7-dd81-4cff-e739-b77ac5d07daa"
      },
      "source": [
        "for i in sampless:\r\n",
        "  print(incorrect_predictions[i][0],\"_\",incorrect_predictions[i][1],'_',incorrect_predictions[i][2])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "legal agreement status from aneela i realize cheryl has been working on _ some of this _ today is cell\n",
            "project granite update thanks mitch paul kaufman ect _ pm to _ ric fax\n",
            "dow jones article re eei i will call _ mark golden to respond _ ing new counterparties\n",
            "ut update please let me know by friday if you _ plan to _ have any\n",
            "hey you are won _ derful person by _ dering how all\n",
            "wellhead meeting ed mcmichael would _ like to have a _ ing for another\n",
            "therefore you will soon _ have the option _ er for or\n",
            "structured sales to ca chris thanks a lot for the info and _ the help _ rew energy manager\n",
            "aol messenger.. ok now what _ i signed up downloaded _ all now is now\n",
            "green card permanent resident alien best regards bobbi international human resources telephone _ work space eb _ phone fax pager\n",
            "ca iso newsflash on dg i spoke with the ca _ iso attorney _ ence in europe\n",
            "puc public participation hearing to participate you must arrive early and _ sign in to _ rea for further\n",
            "fw super bowl you were all chosen for _ a reason _ ward to\n",
            "demand charges and pricing for jeff we should probably _ chat about the _ start this alternative\n",
            "possible candidate please forward to _ appropriate parties if there _ anyone soon\n",
            "dr.evil just heard some _ austin powers sound bites _ thing about it\n",
            "days left to make your thanks again for _ your support and participation _ ward to working\n",
            "ebs clec meeting hi sue you are _ correct that we _ going to be\n",
            "i will try _ to find out more _ ing you and\n",
            "bravo natural resources please prepare an amendment per terms of _ this credit worksheet _ the enron guaranty\n",
            "in my savings plan _ matching other ideas _ ned million of\n",
            "i did not get home _ until late _ tix after work\n",
            "george w is new limo thought you might _ be able to appreciate _ try and play golf\n",
            "research group move to the be sure to ever _ ything with your _ yone in the\n",
            "aps to pinnacle west we have been _ getting a lot of _ selected with these people\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTUm-7fCTref"
      },
      "source": [
        "infile = open('incorrect_preds_att.pkl','rb')\r\n",
        "incorrect_predictions_att = pickle.load(infile)\r\n",
        "infile.close()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suwk78t5YDPq"
      },
      "source": [
        "import random\r\n",
        "sampless_att = random.sample(range(len(incorrect_predictions_att)), 25)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1W6xO6iHSL2Y",
        "outputId": "25888ddc-ef6e-4976-f909-9e9aaf9ad9eb"
      },
      "source": [
        "for i in sampless_att:\r\n",
        "  print(incorrect_predictions_att[i][0],\"_\",incorrect_predictions_att[i][1],'_',incorrect_predictions_att[i][2])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "congratulations sally i just read the _ email announcing _ re from origination\n",
            "land option new york correct on the edgecombe _ north carolina thing _ ent z basis\n",
            "marking chairs we will let you know when this will _ take place _ not be processed\n",
            "weather review the weather sho _ uld be cash _ ws those authority\n",
            "please please please it is a potato peeler _ my favorite _ one for the\n",
            "wellhead deals changed daren o neal the attached spreadsheet represents _ deal volumes changed _ the gas valuation\n",
            "fw top imbalances for october bcf long to the pipe _ position on _ line for the\n",
            "ipams legal legislative and regulatory committee will _ meet wednesday november _ iams through monday\n",
            "legal support for sao paulo do you still _ want to do it _ have any thoughts or\n",
            "phone for steve sorry the on his _ printed itinerary was _ age look at\n",
            "share information about yourself create _ your own _ ed at http\n",
            "dept. of justice interview eol haedicke said you knew about _ this and _ one is reference\n",
            "liz are dia _ monds still available _ mond level hire\n",
            "web file it should be called _ kern expansion economics _ and flash plans\n",
            "reliant q eol gd nymex can you adjust _ in tagg thanks joe _ ed to this\n",
            "items for discussion price risk i have a _ lot of files organized _ ized similar for\n",
            "com cc subject where _ is my buddy _ i do not\n",
            "cash move john please print sign and return in the envelope you _ send us tomorrow _ approve them for\n",
            "fw set the hook who is up for _ an offshore fishing _ warded on my\n",
            "can you come early satan is on tra _ il fast and _ ding or something\n",
            "christmas party we have a _ long way to go _ lot of him at\n",
            "bridgeline cash use approval request attached below is the cash _ use approval _ eadsheet for november\n",
            "vlady i can not _ believe you finally got _ get it until i\n",
            "so no messages from you _ all day _ rs your family\n",
            "perfect.com i hope we get to talk some more and exchange _ ideas about b _ people to help\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieiW5y8xPSl_"
      },
      "source": [
        "From the examples above from both normal encoder decoder model and attention model, we can see multiple cases,\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lzbMy65Dbnv"
      },
      "source": [
        "Input | Original | Predicted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYas6psFCPXU"
      },
      "source": [
        "##Prediction is better than the original\r\n",
        "\r\n",
        "  - can you send me an _ enail with _ email confirming\r\n",
        "\r\n",
        "  - we had to leave _ the severance date _ a few hours\r\n",
        "\r\n",
        "  - new deal check out model can you schedule minutes after _ trading on _ noon to\r\n",
        "\r\n",
        "  - i also need the _ delivery points for _ se up to\r\n",
        "\r\n",
        "- possible candidate please forward to _ appropriate parties if there _ anyone soon\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYLSA6iJCT0F"
      },
      "source": [
        "## Since the sentence was long, model wasn't able to learn properly\r\n",
        "\r\n",
        "  - eol hold list for global the counterparties replacing these entities are still being reviewed by credit _ legal and contracts _ on enron corp\r\n",
        "\r\n",
        "  - hpl meter hughes cmp currently these volumes are being recorded to _ the hpl strangers _ gas counterparties\r\n",
        "\r\n",
        "- no management committee meeting on afternoon there will not be a meeting _ on tuesday following _ ing the nov\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3QXTO8GCT-P"
      },
      "source": [
        "## Prediction is also meaningful as original but both doesn't match\r\n",
        "\r\n",
        "  - hey matt i gave her my digits and _ told her to call _ my number is\r\n",
        "\r\n",
        "  - dabhol steve please look at the _ link below _ se comments back\r\n",
        "\r\n",
        "  - i really meant to call you back _ but could not _ to work on\r\n",
        "\r\n",
        "  - how are you feeling i _ hope well _ am coming\r\n",
        "\r\n",
        "  - share information about yourself create _ your own _ ed at http\r\n",
        "\r\n",
        "  - do you yahoo find a _ job post _ great connection\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvNs2NukCilQ"
      },
      "source": [
        "##The input or original is rare to occur i.e. so specific\r\n",
        "\r\n",
        "  - tagg exchange users the users i would start with _ are todd warwick frank _ out a little point\r\n",
        "\r\n",
        "  - mobil beaumont rebecca i spoke with brian nichols about the _ august preliminary _ online matter\r\n",
        "\r\n",
        "- pg e filed testimony and i will forward our protest _ and iep _ ing this morning\r\n",
        "\r\n",
        "- ena vng contract leg mdq z i might be looking _ in the wrong _ ing with this\r\n",
        "\r\n",
        "- what are the klan is tow _ ard asians lc _ er at el\r\n",
        "\r\n",
        "- analyst and associate dinner august no later than close _ of business monday _ ing the hour\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUj3izdkCnJP"
      },
      "source": [
        "##Some examples look easy but model didn't predict well\r\n",
        "\r\n",
        "  - i think you said tomorrow at pm would _ work for _ ing to turn\r\n",
        "\r\n",
        "  - new email id therefore please update _ your address books to _ ation on my\r\n",
        "  \r\n",
        "  - real option conference i would like to attend _ this conference _ ing the above\r\n",
        "\r\n",
        "- invoices i was planning _ on calling you after _ ing for jeff\r\n",
        "\r\n",
        "- i will try _ to find out more _ ing you and\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0FQb4HSCOYp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZkE5O3KSRGJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}